# Глава 61: FinGPT — Открытая Финансовая Языковая Модель

В этой главе рассматривается **FinGPT** — открытая большая языковая модель, специально разработанная для финансовой сферы. В отличие от проприетарных моделей, таких как BloombergGPT, FinGPT предоставляет доступные и настраиваемые решения для задач финансовой обработки естественного языка, включая анализ настроений, понимание новостей и генерацию торговых сигналов.

<p align="center">
<img src="https://i.imgur.com/QVZ8kXp.png" width="70%">
</p>

## Содержание

1. [Введение в FinGPT](#введение-в-fingpt)
    * [Почему открытые финансовые LLM?](#почему-открытые-финансовые-llm)
    * [Обзор архитектуры FinGPT](#обзор-архитектуры-fingpt)
    * [Ключевые особенности](#ключевые-особенности)
2. [Подход к обучению FinGPT](#подход-к-обучению-fingpt)
    * [Дата-центричная архитектура](#дата-центричная-архитектура)
    * [Обучение с подкреплением на основе цен акций (RLSP)](#обучение-с-подкреплением-на-основе-цен-акций-rlsp)
    * [Тонкая настройка с помощью LoRA](#тонкая-настройка-с-помощью-lora)
3. [Торговые приложения](#торговые-приложения)
    * [Анализ настроений](#анализ-настроений)
    * [Торговые сигналы на основе новостей](#торговые-сигналы-на-основе-новостей)
    * [Интеграция с робо-советниками](#интеграция-с-робо-советниками)
    * [Анализ криптовалют](#анализ-криптовалют)
4. [Практические примеры](#практические-примеры)
5. [Реализация на Rust](#реализация-на-rust)
6. [Реализация на Python](#реализация-на-python)
7. [Сравнение с другими моделями](#сравнение-с-другими-моделями)
8. [Лучшие практики](#лучшие-практики)
9. [Ресурсы](#ресурсы)

## Введение в FinGPT

FinGPT — это открытая инициатива фонда AI4Finance Foundation, направленная на демократизацию финансовых больших языковых моделей. В то время как проприетарные модели, такие как BloombergGPT, требуют значительных ресурсов и недоступны публично, FinGPT предоставляет фреймворк для создания и тонкой настройки финансовых LLM с использованием публично доступных данных и открытых базовых моделей.

### Почему открытые финансовые LLM?

```
ПРОБЛЕМЫ С ПРОПРИЕТАРНЫМИ ФИНАНСОВЫМИ LLM:
┌──────────────────────────────────────────────────────────────────┐
│  1. ДОСТУПНОСТЬ                                                   │
│     BloombergGPT: Недоступен публично                             │
│     FinGPT: Открытый код, любой может использовать и изменять     │
├──────────────────────────────────────────────────────────────────┤
│  2. НАСТРАИВАЕМОСТЬ                                               │
│     BloombergGPT: Фиксированная модель, без тонкой настройки      │
│     FinGPT: Настройка под ваш конкретный случай использования     │
├──────────────────────────────────────────────────────────────────┤
│  3. АКТУАЛЬНОСТЬ ДАННЫХ                                           │
│     Проприетарные: Данные обучения могут устареть                 │
│     FinGPT: Непрерывные обновления с пайплайнами реальных данных  │
├──────────────────────────────────────────────────────────────────┤
│  4. СТОИМОСТЬ                                                     │
│     Проприетарные: Дорогие API, лицензионные платежи              │
│     FinGPT: Бесплатно для использования, хостинга и модификации   │
├──────────────────────────────────────────────────────────────────┤
│  5. ПРОЗРАЧНОСТЬ                                                  │
│     Проприетарные: Черный ящик, неизвестные смещения              │
│     FinGPT: Полная видимость данных и методов обучения            │
└──────────────────────────────────────────────────────────────────┘
```

### Обзор архитектуры FinGPT

FinGPT использует модульный, дата-центричный подход:

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                           АРХИТЕКТУРА FinGPT                                  │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                        СЛОЙ ДАННЫХ                                       │ │
│  │  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐    │ │
│  │  │ Новостные    │ │ SEC-отчеты   │ │ Соцсети      │ │ Рыночные     │    │ │
│  │  │ API          │ │ (EDGAR,      │ │ (Twitter,    │ │ данные       │    │ │
│  │  │ (Reuters)    │ │  10-K/Q)     │ │  Reddit)     │ │ (Bybit)      │    │ │
│  │  └──────┬───────┘ └──────┬───────┘ └──────┬───────┘ └──────┬───────┘    │ │
│  │         │                │                │                │             │ │
│  │         └────────────────┴────────────────┴────────────────┘             │ │
│  │                                    │                                      │ │
│  │                                    ▼                                      │ │
│  │  ┌──────────────────────────────────────────────────────────────────┐    │ │
│  │  │              ИНЖЕНЕРИЯ И ПРЕДОБРАБОТКА ДАННЫХ                      │    │ │
│  │  │   • Очистка и нормализация финансового текста                     │    │ │
│  │  │   • Извлечение структурированных данных (сущности, числа, даты)   │    │ │
│  │  │   • Создание наборов данных для обучения по инструкциям           │    │ │
│  │  └──────────────────────────────────────────────────────────────────┘    │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                    │                                          │
│                                    ▼                                          │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                        СЛОЙ МОДЕЛИ                                       │ │
│  │  ┌──────────────────────────────────────────────────────────────────┐   │ │
│  │  │                   ВАРИАНТЫ БАЗОВЫХ МОДЕЛЕЙ                        │   │ │
│  │  │   LLaMA-2 (7B/13B/70B) | Falcon | MPT | Mistral | ChatGLM        │   │ │
│  │  └────────────────────────────────┬─────────────────────────────────┘   │ │
│  │                                   │                                      │ │
│  │                                   ▼                                      │ │
│  │  ┌──────────────────────────────────────────────────────────────────┐   │ │
│  │  │              МЕТОДЫ ТОНКОЙ НАСТРОЙКИ                               │   │ │
│  │  │   ┌─────────────┐   ┌─────────────┐   ┌─────────────────────┐   │   │ │
│  │  │   │   LoRA      │   │    QLoRA    │   │ Полная настройка    │   │   │ │
│  │  │   │ (Низкоранг. │   │ (Квантов.   │   │ (Ресурсоемкая)      │   │   │ │
│  │  │   │  адаптеры)  │   │   LoRA)     │   │                     │   │   │ │
│  │  │   └─────────────┘   └─────────────┘   └─────────────────────┘   │   │ │
│  │  └──────────────────────────────────────────────────────────────────┘   │ │
│  │                                   │                                      │ │
│  │                                   ▼                                      │ │
│  │  ┌──────────────────────────────────────────────────────────────────┐   │ │
│  │  │              ОБУЧЕНИЕ С ПОДКРЕПЛЕНИЕМ                              │   │ │
│  │  │   RLSP - выравнивание прогнозов с реальной доходностью            │   │ │
│  │  └──────────────────────────────────────────────────────────────────┘   │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                    │                                          │
│                                    ▼                                          │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                     СЛОЙ ПРИЛОЖЕНИЙ                                      │ │
│  │  ┌────────────┐  ┌────────────┐  ┌────────────┐  ┌────────────────────┐ │ │
│  │  │ Анализ     │  │  Торговые  │  │   Робо-    │  │ Оценка рисков     │ │ │
│  │  │ настроений │  │  сигналы   │  │  советник  │  │ и комплаенс       │ │ │
│  │  └────────────┘  └────────────┘  └────────────┘  └────────────────────┘ │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
└──────────────────────────────────────────────────────────────────────────────┘
```

### Ключевые особенности

1. **Дата-центричный дизайн**
   - Автоматизированные пайплайны данных для финансовой информации в реальном времени
   - Поддержка множества источников данных (новости, отчеты, соцсети)
   - Встроенная очистка и предобработка данных

2. **Эффективная тонкая настройка**
   - LoRA и QLoRA для параметрически-эффективного обучения
   - Обучение на потребительских GPU (RTX 3090, 4090)
   - Быстрая адаптация к новым доменам

3. **Новые методы обучения**
   - RLSP (обучение с подкреплением на основе цен акций)
   - Выравнивание выходов модели с реальной рыночной доходностью
   - Улучшенная генерация торговых сигналов

4. **Множество базовых моделей**
   - Поддержка LLaMA-2, Falcon, MPT, Mistral
   - Выбор в зависимости от вашего оборудования и требований
   - Легкая замена и эксперименты

## Подход к обучению FinGPT

### Дата-центричная архитектура

FinGPT делает акцент на качестве и актуальности данных, а не на размере модели:

```python
# Концепция пайплайна данных FinGPT
class FinGPTDataPipeline:
    """
    Получение и обработка данных в реальном времени для FinGPT.
    """

    def __init__(self):
        self.sources = {
            "news": ["reuters", "finnhub", "alpaca_news"],
            "filings": ["sec_edgar"],
            "social": ["twitter", "reddit_wallstreetbets"],
            "market": ["yahoo_finance", "binance", "bybit"]
        }

    def collect_data(self, source_type: str, symbols: list):
        """Сбор данных из указанных источников."""
        pass

    def preprocess(self, raw_data):
        """
        Этапы предобработки:
        1. Удаление дубликатов
        2. Очистка HTML/спецсимволов
        3. Нормализация дат и чисел
        4. Извлечение сущностей
        5. Создание формата instruction-following
        """
        pass

    def create_training_samples(self, data, task_type: str):
        """
        Создание обучающих примеров.

        Формат примера:
        {
            "instruction": "Проанализируйте настроение этого заголовка.",
            "input": "Apple отчитывается о рекордной выручке за Q4",
            "output": "ПОЗИТИВНОЕ. Заголовок указывает на сильные финансовые..."
        }
        """
        pass
```

### Обучение с подкреплением на основе цен акций (RLSP)

Ключевое нововведение FinGPT — это RLSP, который выравнивает прогнозы модели с реальными рыночными результатами:

```
RLSP: ОБУЧЕНИЕ С ПОДКРЕПЛЕНИЕМ НА ОСНОВЕ ЦЕН АКЦИЙ
═══════════════════════════════════════════════════════════════════════════════

ТРАДИЦИОННЫЙ ПОДХОД (Метки настроений):
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                              │
│  Текст новости ──────► LLM ──────► Настроение ──────► Торговый сигнал       │
│                         │           (Людские метки)                          │
│                         │                                                    │
│  Проблема: Людские метки могут не коррелировать с реальным движением цен!   │
│                                                                              │
│  "Apple сохраняет прогноз" → Человек: НЕЙТРАЛЬНО → Акция: ВВЕРХ на 5%       │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

ПОДХОД RLSP (Обратная связь от цен акций):
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                              │
│  Текст новости ──────► LLM ──────► Прогноз ──────► Сравнение с              │
│                         │                          Реальной доходностью      │
│                         │                                   │                │
│                         │◄─────────────── Награда/Потеря ◄──┘                │
│                                                                              │
│  Модель учится, какие новости РЕАЛЬНО двигают цены!                          │
│                                                                              │
│  "Apple сохраняет прогноз" → RLSP: +0.7 сигнал → Акция: ВВЕРХ на 5% ✓       │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

Концепция реализации RLSP:

```python
def compute_rlsp_reward(
    prediction: float,      # Прогноз направления модели (-1 до 1)
    actual_return: float,   # Реальная доходность акции
    confidence: float       # Уверенность модели
) -> float:
    """
    Расчет награды для обучения RLSP.

    Args:
        prediction: Направленный прогноз модели
        actual_return: Реальная рыночная доходность
        confidence: Оценка уверенности модели

    Returns:
        Сигнал награды для RL-обучения
    """
    # Награда за правильное предсказание направления
    direction_match = (prediction * actual_return) > 0

    if direction_match:
        # Положительная награда, масштабированная уверенностью и величиной
        reward = abs(actual_return) * confidence
    else:
        # Штраф за неверное направление
        reward = -abs(actual_return) * confidence

    return reward
```

### Тонкая настройка с помощью LoRA

FinGPT использует LoRA для эффективной тонкой настройки:

```
LoRA: ПАРАМЕТРИЧЕСКИ-ЭФФЕКТИВНАЯ ТОНКАЯ НАСТРОЙКА
═══════════════════════════════════════════════════════════════════════════════

ПОЛНАЯ ТОНКАЯ НАСТРОЙКА (Традиционная):
┌─────────────────────────────────────────────────────────────────────────────┐
│  Базовая модель: 7B параметров ──► Обновление ВСЕХ 7B параметров            │
│                                                                              │
│  Требования:                                                                 │
│  • GPU-память: 80GB+ (A100)                                                  │
│  • Время обучения: Дни или недели                                            │
│  • Стоимость: $$$$$                                                          │
└─────────────────────────────────────────────────────────────────────────────┘

LoRA НАСТРОЙКА (FinGPT):
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                              │
│  Базовая модель (Заморожена): 7B    +     LoRA-адаптеры: 8M параметров      │
│         ┌────────────────────┐              ┌────────────────┐               │
│         │                    │              │                │               │
│         │   W (оригинал)     │      +       │   BA (LoRA)    │               │
│         │   [4096 x 4096]    │              │   [4096 x r]   │               │
│         │    (ЗАМОРОЖЕН)     │              │   x [r x 4096] │               │
│         │                    │              │   r = 8 (ранг) │               │
│         └────────────────────┘              │   (ОБУЧАЕМЫЕ)  │               │
│                                             └────────────────┘               │
│                                                                              │
│  Требования:                                                                 │
│  • GPU-память: 16GB (RTX 4090)                                              │
│  • Время обучения: Часы                                                      │
│  • Стоимость: $                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

Конфигурация LoRA для FinGPT:

```python
from peft import LoraConfig, get_peft_model

# Конфигурация LoRA для FinGPT
lora_config = LoraConfig(
    r=8,                       # Ранг матриц адаптации
    lora_alpha=32,             # Коэффициент масштабирования
    target_modules=[           # Какие слои адаптировать
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj"
    ],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# Применение LoRA к базовой модели
model = get_peft_model(base_model, lora_config)

# Вывод обучаемых параметров
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
total_params = sum(p.numel() for p in model.parameters())
print(f"Обучаемые: {trainable_params:,} / {total_params:,} = {100*trainable_params/total_params:.2f}%")
# Вывод: Обучаемые: 8,388,608 / 6,738,415,616 = 0.12%
```

## Торговые приложения

### Анализ настроений

FinGPT отлично справляется с анализом финансовых настроений:

```python
# Пример: промпт анализа настроений FinGPT
prompt = """Инструкция: Какое настроение этой новости? Выберите ответ из {негативное/нейтральное/позитивное}.

Ввод: NVIDIA сообщает о рекордной выручке благодаря спросу на AI-чипы, акции выросли на 10%.

Ответ:"""

# Ответ FinGPT: "позитивное"
```

**Результаты бенчмарков (Точность):**

| Датасет | FinGPT-LLaMA | FinBERT | ChatGPT | BloombergGPT |
|---------|-------------|---------|---------|--------------|
| FPB (Financial PhraseBank) | **87.2%** | 86.5% | 78.3% | - |
| FiQA-SA | **85.4%** | 83.7% | 73.2% | - |
| TFNS (Twitter Financial) | **82.1%** | 80.3% | 71.5% | - |
| Headlines | **79.8%** | 77.2% | 68.4% | - |

### Торговые сигналы на основе новостей

Преобразование настроений в действенные сигналы:

```python
class FinGPTSignalGenerator:
    """Генерация торговых сигналов на основе анализа настроений FinGPT."""

    def __init__(self, model, confidence_threshold: float = 0.7):
        self.model = model
        self.confidence_threshold = confidence_threshold

        # Маппинг сигналов
        self.sentiment_to_signal = {
            "positive": 1.0,
            "neutral": 0.0,
            "negative": -1.0
        }

    def generate_signal(
        self,
        news: str,
        symbol: str
    ) -> dict:
        """
        Генерация торгового сигнала из новостного текста.

        Returns:
            dict с сигналом, уверенностью и обоснованием
        """
        # Получение прогноза FinGPT
        prompt = self._create_prompt(news)
        response = self.model.generate(prompt)

        sentiment, confidence = self._parse_response(response)

        if confidence < self.confidence_threshold:
            return {
                "symbol": symbol,
                "signal": 0.0,
                "action": "HOLD",
                "confidence": confidence,
                "reason": "Низкая уверенность прогноза"
            }

        signal = self.sentiment_to_signal[sentiment] * confidence

        return {
            "symbol": symbol,
            "signal": signal,
            "action": "BUY" if signal > 0.3 else "SELL" if signal < -0.3 else "HOLD",
            "confidence": confidence,
            "reason": f"Настроение: {sentiment}"
        }
```

### Анализ криптовалют

FinGPT поддерживает анализ крипторынка с данными Bybit:

```python
class CryptoAnalyzer:
    """Анализ криптовалютных рынков с помощью FinGPT."""

    def __init__(self, fingpt_model, bybit_client):
        self.model = fingpt_model
        self.bybit = bybit_client

    async def analyze_crypto_news(
        self,
        symbol: str = "BTCUSDT",
        news_items: list = None
    ) -> dict:
        """
        Анализ крипто-новостей и генерация торговых сигналов.

        Args:
            symbol: Торговая пара (например, BTCUSDT)
            news_items: Список новостных заголовков

        Returns:
            Анализ с настроением и сигналом
        """
        # Получение данных о ценах с Bybit
        price_data = await self.bybit.get_klines(
            symbol=symbol,
            interval="1h",
            limit=24
        )

        # Анализ каждой новости
        signals = []
        for news in news_items:
            signal = self._analyze_single_news(news, symbol)
            signals.append(signal)

        # Агрегация сигналов
        avg_signal = sum(s["signal"] for s in signals) / len(signals)

        return {
            "symbol": symbol,
            "current_price": price_data[-1]["close"],
            "24h_change": self._calc_change(price_data),
            "news_signal": avg_signal,
            "recommendation": self._get_recommendation(avg_signal),
            "individual_signals": signals
        }
```

## Практические примеры

Полные примеры доступны в каталоге `python/examples/`:

- `01_sentiment_demo.py` — Анализ настроений финансовых текстов
- `02_signal_generation.py` — Генерация торговых сигналов из новостей
- `03_crypto_bybit.py` — Анализ криптовалют с данными Bybit
- `04_backtest_demo.py` — Бэктестинг стратегий на основе FinGPT

## Реализация на Rust

```
rust_fingpt/
├── Cargo.toml
├── README.md
├── src/
│   ├── lib.rs              # Основные экспорты библиотеки
│   ├── sentiment.rs        # Анализ настроений
│   ├── signals.rs          # Генерация торговых сигналов
│   ├── backtest.rs         # Движок бэктестинга
│   ├── data.rs             # Загрузка рыночных данных
│   ├── api.rs              # Клиенты внешних API
│   └── error.rs            # Типы ошибок
└── src/bin/
    ├── sentiment_demo.rs   # Демо анализа настроений
    ├── signal_demo.rs      # Демо генерации сигналов
    ├── crypto_demo.rs      # Крипто-анализ с Bybit
    └── backtest_demo.rs    # Демо бэктестинга
```

### Быстрый старт (Rust)

```bash
cd rust_fingpt

# Запуск демо анализа настроений
cargo run --bin sentiment_demo

# Генерация торговых сигналов
cargo run --bin signal_demo -- --symbol AAPL

# Крипто-анализ с Bybit
cargo run --bin crypto_demo -- --symbol BTCUSDT

# Запуск бэктеста
cargo run --bin backtest_demo -- --start 2024-01-01 --end 2024-12-31
```

## Реализация на Python

```
python/
├── __init__.py
├── fingpt_sentiment.py    # Анализ настроений
├── signals.py             # Генерация торговых сигналов
├── backtest.py            # Движок бэктестинга
├── data_loader.py         # Утилиты загрузки данных
├── bybit_client.py        # Клиент API Bybit
├── requirements.txt       # Зависимости
└── examples/
    ├── 01_sentiment_demo.py
    ├── 02_signal_generation.py
    ├── 03_crypto_bybit.py
    └── 04_backtest_demo.py
```

### Быстрый старт (Python)

```bash
cd python

# Установка зависимостей
pip install -r requirements.txt

# Запуск анализа настроений
python examples/01_sentiment_demo.py

# Генерация торговых сигналов
python examples/02_signal_generation.py

# Крипто-анализ
python examples/03_crypto_bybit.py

# Запуск бэктеста
python examples/04_backtest_demo.py
```

## Сравнение с другими моделями

| Особенность | FinGPT | BloombergGPT | FinBERT | ChatGPT |
|-------------|--------|--------------|---------|---------|
| **Открытый код** | ✅ Да | ❌ Нет | ✅ Да | ❌ Нет |
| **Финансовое обучение** | ✅ Обширное | ✅ Обширное | ✅ Финансовое | ❌ Общее |
| **Настраиваемость** | ✅ LoRA настройка | ❌ Фиксирован | ✅ Настраиваемый | ❌ Только API |
| **Реальные данные** | ✅ Пайплайны данных | ❌ Статическое | ❌ Статическое | ❌ Отсечка знаний |
| **RLSP обучение** | ✅ Да | ❌ Нет | ❌ Нет | ❌ Нет |
| **Размеры моделей** | 7B-70B | 50B | 110M | ~1T |
| **Требования к оборудованию** | Потребительский GPU | Датацентр | Низкие | API |
| **Стоимость** | Бесплатно | $$$$$ | Бесплатно | $$ |

## Лучшие практики

### Когда использовать FinGPT

**Идеальные случаи использования:**
- Анализ настроений финансовых новостей
- Построение собственных пайплайнов торговых сигналов
- Исследования и эксперименты
- Приложения с ограниченным бюджетом
- Собственный хостинг

**Рассмотрите альтернативы когда:**
- Требуется сверхнизкая задержка (используйте FinBERT)
- Критична максимальная точность (рассмотрите коммерческие решения)
- Нет опыта в ML (используйте ChatGPT API)

### Советы по тонкой настройке

1. **Качество данных**
   ```python
   # Всегда очищайте и валидируйте обучающие данные
   def clean_financial_text(text: str) -> str:
       # Удаление HTML
       text = re.sub(r'<[^>]+>', '', text)
       # Нормализация пробелов
       text = ' '.join(text.split())
       # Сохранение финансовых сущностей
       return text
   ```

2. **Конфигурация LoRA**
   ```python
   # Рекомендуемые настройки для FinGPT
   lora_config = LoraConfig(
       r=8,                    # Начните с r=8, увеличьте при недообучении
       lora_alpha=32,          # alpha = 4 * r — распространенная практика
       target_modules=[        # Целевые слои внимания
           "q_proj", "v_proj", "k_proj", "o_proj"
       ],
       lora_dropout=0.05,      # Легкая регуляризация
   )
   ```

3. **Гиперпараметры обучения**
   ```python
   training_args = TrainingArguments(
       learning_rate=2e-4,     # Выше, чем при полной настройке
       num_train_epochs=3,     # Обычно достаточно
       per_device_train_batch_size=4,
       gradient_accumulation_steps=4,  # Эффективный batch=16
       warmup_steps=100,
       fp16=True,              # Смешанная точность
   )
   ```

## Ресурсы

### Научные статьи

- [FinGPT: Open-Source Financial Large Language Models](https://arxiv.org/abs/2306.06031) — Оригинальная статья FinGPT (2023)
- [FinGPT-HPC: Efficient Pretraining and Fine-tuning](https://arxiv.org/abs/2402.12659) — Высокопроизводительные вычисления для FinGPT
- [Instruct-FinGPT: Financial Sentiment Analysis](https://arxiv.org/abs/2306.12659) — Обучение по инструкциям для финансов

### Репозитории

- [FinGPT Official](https://github.com/AI4Finance-Foundation/FinGPT) — Основной репозиторий FinGPT
- [FinRL](https://github.com/AI4Finance-Foundation/FinRL) — Сопутствующая библиотека RL
- [FinNLP](https://github.com/AI4Finance-Foundation/FinNLP) — Инструменты финансовой NLP

### Связанные главы

- [Глава 62: BloombergGPT Trading](../62_bloomberggpt_trading) — Проприетарная альтернатива
- [Глава 241: FinBERT Sentiment](../241_finbert_sentiment) — Меньшая, быстрая модель
- [Глава 67: LLM Sentiment Analysis](../67_llm_sentiment_analysis) — Глубокий анализ настроений
- [Глава 70: Fine-tuning LLM for Finance](../70_fine_tuning_llm_finance) — Продвинутая настройка

---

## Уровень сложности

**Средний — Продвинутый**

Предварительные требования:
- Понимание архитектуры трансформеров и LLM
- Опыт программирования на Python
- Базовые знания о финансовых рынках
- Знакомство с PyTorch (для тонкой настройки)

## Ссылки

1. Yang, H., et al. (2023). "FinGPT: Open-Source Financial Large Language Models." arXiv:2306.06031
2. Liu, X., et al. (2023). "FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications."
3. Wu, S., et al. (2023). "BloombergGPT: A Large Language Model for Finance." arXiv:2303.17564
4. Araci, D. (2019). "FinBERT: Financial Sentiment Analysis with Pre-trained Language Models."
