# Линейные модели: от факторов риска к прогнозам доходности активов

Семейство линейных моделей представляет собой один из наиболее полезных классов гипотез. Многие алгоритмы машинного обучения, широко применяемые в алгоритмической торговле, опираются на линейные предикторы, поскольку они эффективно обучаются, относительно устойчивы к зашумлённым финансовым данным и имеют прочную связь с теорией финансов. Линейные предикторы также интуитивно понятны, легко интерпретируются и часто достаточно хорошо описывают данные или, как минимум, служат хорошей базовой моделью.

Линейная регрессия известна уже более 200 лет — с тех пор как Лежандр и Гаусс применили её в астрономии и начали изучать её статистические свойства. С тех пор появилось множество расширений, адаптировавших модель линейной регрессии и базовый метод наименьших квадратов (МНК) для обучения её параметров:

- **Обобщённые линейные модели** (GLM) расширяют область применения, допуская переменные отклика с распределением ошибок, отличным от нормального. GLM включают пробит- и логит-модели для категориальных переменных отклика, которые используются в задачах классификации.
- **Робастные методы оценивания** позволяют проводить статистический вывод в случаях, когда данные нарушают базовые предположения — например, из-за корреляции во времени или между наблюдениями. Это часто происходит с панельными данными, содержащими повторные наблюдения по одним и тем же объектам, таким как исторические доходности по вселенной активов.
- **Методы сжатия** (shrinkage) направлены на улучшение прогностической эффективности линейных моделей. Они используют штраф за сложность, который смещает коэффициенты модели с целью снижения её дисперсии и улучшения прогностической способности на новых данных.

На практике линейные модели применяются к задачам регрессии и классификации для целей статистического вывода и прогнозирования. Многочисленные модели ценообразования активов были разработаны академическими и отраслевыми исследователями с использованием линейной регрессии. Применения включают выявление значимых факторов, определяющих доходность активов для лучшего управления рисками и эффективностью, а также прогнозирование доходности на различных временных горизонтах. Задачи классификации, в свою очередь, включают прогнозирование направления движения цены. В этой главе мы рассмотрим следующие темы:

## Содержание

1. [Линейная регрессия: от вывода к прогнозированию](#линейная-регрессия-от-вывода-к-прогнозированию)
2. [Базовая модель: множественная линейная регрессия](#базовая-модель-множественная-линейная-регрессия)
    * [Пример кода: простая и множественная линейная регрессия с `statsmodels` и `scikit-learn`](#пример-кода-простая-и-множественная-линейная-регрессия-с-statsmodels-и-scikit-learn)
3. [Как построить линейную факторную модель](#как-построить-линейную-факторную-модель)
    * [От CAPM к пятифакторной модели Фамы—Френча](#от-capm-к-пятифакторной-модели-фамыфренча)
    * [Получение факторов риска](#получение-факторов-риска)
    * [Пример кода: регрессия Фамы—Макбета](#пример-кода-регрессия-фамымакбета)
4. [Методы сжатия: регуляризация для линейной регрессии](#методы-сжатия-регуляризация-для-линейной-регрессии)
    * [Защита от переобучения — регуляризация в линейных моделях](#защита-от-переобучения--регуляризация-в-линейных-моделях)
    * [Гребневая регрессия (Ridge)](#гребневая-регрессия-ridge)
    * [Лассо-регрессия (Lasso)](#лассо-регрессия-lasso)
5. [Как прогнозировать доходность акций с помощью линейной регрессии](#как-прогнозировать-доходность-акций-с-помощью-линейной-регрессии)
    * [Примеры кода: вывод и прогнозирование доходности акций](#примеры-кода-вывод-и-прогнозирование-доходности-акций)
6. [Линейная классификация](#линейная-классификация)
    * [Модель логистической регрессии](#модель-логистической-регрессии)
    * [Пример кода: статистический вывод с помощью statsmodels](#пример-кода-статистический-вывод-с-помощью-statsmodels)
    * [Примеры кода: использование логистической регрессии для прогнозирования](#примеры-кода-использование-логистической-регрессии-для-прогнозирования)
7. [Литература](#литература)


## Линейная регрессия: от вывода к прогнозированию

В этом разделе представлены базовые методы линейных моделей для работы с кросс-секционными и панельными данными, а также важные улучшения, обеспечивающие точные оценки при нарушении ключевых предположений. Далее эти методы иллюстрируются на примере оценки факторных моделей, которые повсеместно используются при разработке алгоритмических торговых стратегий. В заключение раздел фокусируется на методах регуляризации.

- [Вводный курс эконометрики](http://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf), Вулдридж, 2012

## Базовая модель: множественная линейная регрессия

В этом разделе представлена спецификация модели и целевая функция, методы обучения её параметров, статистические предположения, позволяющие проводить статистический вывод, диагностика этих предположений, а также расширения для адаптации модели к ситуациям, когда эти предположения нарушаются. Содержание включает:

- Как сформулировать и обучить модель
- Теорема Гаусса—Маркова
- Как проводить статистический вывод
- Как диагностировать и устранять проблемы
- Как выполнять линейную регрессию на практике

### Пример кода: простая и множественная линейная регрессия с `statsmodels` и `scikit-learn`

Ноутбук [linear_regression_intro](01_linear_regression_intro.ipynb) демонстрирует простую и множественную модель линейной регрессии, последнюю — с использованием как МНК, так и градиентного спуска на базе `statsmodels` и `scikit-learn`.

## Как построить линейную факторную модель

Алгоритмические торговые стратегии используют линейные факторные модели для количественной оценки связи между доходностью актива и источниками риска, которые являются основными драйверами этой доходности. Каждый фактор риска несёт премию, и общая доходность актива может ожидаться как взвешенное среднее этих премий за риск.

### От CAPM к пятифакторной модели Фамы—Френча

Факторы риска были ключевым компонентом количественных моделей со времён модели оценки капитальных активов (CAPM), которая объясняла ожидаемую доходность всех активов через их подверженность единственному фактору — ожидаемой избыточной доходности рынка в целом над безрисковой ставкой.

Это отличается от классического фундаментального анализа в стиле Додда и Грэма, где доходность зависит от характеристик фирмы. Обоснование состоит в том, что в совокупности инвесторы не могут устранить этот так называемый систематический риск путём диверсификации. Следовательно, в состоянии равновесия они требуют компенсацию за владение активом, соразмерную его систематическому риску. Модель подразумевает, что при эффективных рынках, где цены немедленно отражают всю публичную информацию, не должно быть доходности, превосходящей с поправкой на риск.

### Получение факторов риска

[Факторы риска Фамы—Френча](http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html) рассчитываются как разница в доходности диверсифицированных портфелей с высокими или низкими значениями метрик, отражающих данный фактор риска. Эти доходности получаются путём сортировки акций по этим метрикам с последующим открытием длинных позиций по акциям выше определённого процентиля и коротких позиций — ниже определённого процентиля. Метрики, связанные с факторами риска, определяются следующим образом:

- Размер: рыночная капитализация (ME)
- Стоимость: балансовая стоимость капитала (BE), делённая на ME
- Операционная рентабельность (OP): выручка минус себестоимость проданных товаров / активы
- Инвестиции: инвестиции / активы

Фама и Френч предоставляют обновлённые данные по факторам риска и исследовательским портфелям через свой [веб-сайт](http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html), и вы можете использовать библиотеку [pandas_datareader](https://pandas-datareader.readthedocs.io/en/latest/) для получения данных.

### Пример кода: регрессия Фамы—Макбета

Для решения проблемы вывода, вызванной корреляцией остатков, Фама и Макбет предложили двухэтапную методологию кросс-секционной регрессии доходностей на факторы. Двухэтапная регрессия Фамы—Макбета предназначена для оценки премии, вознаграждаемой рынком за подверженность определённому фактору риска. Два этапа состоят из:
- **Первый этап**: N регрессий временных рядов, по одной для каждого актива или портфеля, его избыточной доходности на факторы для оценки факторных нагрузок.
- **Второй этап**: T кросс-секционных регрессий, по одной для каждого временного периода, для оценки премии за риск.

Ноутбук [fama_macbeth](02_fama_macbeth.ipynb) иллюстрирует, как выполнить регрессию Фамы—Макбета, включая использование библиотеки [LinearModels](https://bashtage.github.io/linearmodels/doc/).

## Методы сжатия: регуляризация для линейной регрессии

Когда модель линейной регрессии содержит много коррелированных переменных, их коэффициенты будут плохо определены, поскольку эффект большого положительного коэффициента на сумму квадратов остатков (RSS) может быть компенсирован аналогично большим отрицательным коэффициентом при коррелированной переменной. Следовательно, модель будет иметь тенденцию к высокой дисперсии из-за этого «пространства для манёвра» коэффициентов, что увеличивает риск переобучения модели на выборке.

### Защита от переобучения — регуляризация в линейных моделях

Одна из популярных техник контроля переобучения — регуляризация, которая включает добавление штрафного члена к функции ошибки для предотвращения достижения коэффициентами больших значений. Другими словами, ограничения на размер коэффициентов могут смягчить потенциально негативное влияние на прогнозы вне выборки. Мы встретим методы регуляризации для всех моделей, поскольку переобучение является настолько распространённой проблемой.

В этом разделе мы представим методы сжатия, которые решают две задачи для улучшения подходов к линейным моделям, обсуждённых ранее:
- Точность прогнозирования: низкое смещение, но высокая дисперсия оценок наименьших квадратов предполагает, что ошибка обобщения может быть снижена путём сжатия или обнуления некоторых коэффициентов, тем самым балансируя небольшое увеличение смещения со снижением дисперсии модели.
- Интерпретируемость: большое количество предикторов может усложнить интерпретацию или представление общей картины результатов. Может быть предпочтительнее пожертвовать некоторыми деталями, чтобы ограничить модель меньшим подмножеством параметров с наиболее сильными эффектами.

### Гребневая регрессия (Ridge)

Гребневая регрессия сжимает коэффициенты регрессии, добавляя к целевой функции штраф, равный сумме квадратов коэффициентов, что соответствует L2-норме вектора коэффициентов.

### Лассо-регрессия (Lasso)

Лассо, известное в обработке сигналов как Basis Pursuit, также сжимает коэффициенты путём добавления штрафа к сумме квадратов остатков, но штраф лассо имеет несколько иной эффект. Штраф лассо — это сумма абсолютных значений вектора коэффициентов, что соответствует его L1-норме.

## Как прогнозировать доходность акций с помощью линейной регрессии

В этом разделе мы используем линейную регрессию с регуляризацией и без неё для прогнозирования доходности и генерации торговых сигналов. Для этого мы сначала создаём набор данных, а затем применяем модели линейной регрессии, обсуждённые в предыдущем разделе, чтобы проиллюстрировать их использование с statsmodels и sklearn.

### Примеры кода: вывод и прогнозирование доходности акций

- Ноутбук [preparing_the_model_data](03_preparing_the_model_data.ipynb) выбирает вселенную акций США и создаёт несколько признаков для прогнозирования дневной доходности.
- Ноутбук [statistical_inference_of_stock_returns_with_statsmodels](04_statistical_inference_of_stock_returns_with_statsmodels.ipynb) оценивает несколько моделей линейной регрессии с использованием МНК и библиотеки `statsmodels`.
- Ноутбук [predicting_stock_returns_with_linear_regression](05_predicting_stock_returns_with_linear_regression.ipynb) показывает, как прогнозировать дневную доходность акций с помощью линейной регрессии, а также моделей ridge и lasso с использованием `scikit-learn`.
- Ноутбук [evaluating_signals_using_alphalens](06_evaluating_signals_using_alphalens.ipynb) оценивает прогнозы модели с помощью `alphalens`.

## Линейная классификация

Существует множество различных методов классификации для прогнозирования качественного отклика. В этом разделе мы представим широко используемую логистическую регрессию, которая тесно связана с линейной регрессией. Более сложные методы мы рассмотрим в последующих главах, посвящённых обобщённым аддитивным моделям, включающим деревья решений и случайные леса, а также градиентному бустингу и нейронным сетям.

### Модель логистической регрессии

Модель логистической регрессии возникает из желания моделировать вероятности классов выходной переменной, используя функцию, линейную по x, подобно модели линейной регрессии, и при этом обеспечивая, чтобы они суммировались в единицу и оставались в диапазоне [0, 1], как и ожидается от вероятностей.

В этом разделе мы представляем целевую функцию и функциональную форму модели логистической регрессии и описываем метод обучения. Затем мы иллюстрируем, как использовать логистическую регрессию для статистического вывода на макроданных с помощью statsmodels, и как прогнозировать движения цен с помощью регуляризованной логистической регрессии, реализованной в sklearn.

### Пример кода: статистический вывод с помощью statsmodels

Ноутбук [logistic_regression_macro_data](07_logistic_regression_macro_data.ipynb) иллюстрирует, как выполнить логистическую регрессию на макроданных и провести статистический вывод с помощью [statsmodels](https://www.statsmodels.org/stable/index.html).

### Примеры кода: использование логистической регрессии для прогнозирования

Штраф L1 (лассо) и штраф L2 (ridge) могут использоваться с логистической регрессией. Они имеют тот же эффект сжатия, что и обсуждалось выше, и лассо снова может использоваться для отбора переменных в любой модели линейной регрессии.

Как и в случае с линейной регрессией, важно стандартизировать входные переменные, поскольку регуляризованные модели чувствительны к масштабу. Гиперпараметр регуляризации также требует настройки с помощью кросс-валидации, как и в случае линейной регрессии.

Ноутбук [predicting_price_movements_with_logistic_regression](08_predicting_price_movements_with_logistic_regression.ipynb) демонстрирует, как использовать логистическую регрессию для прогнозирования движения цен акций.

## Литература

- [Риск, доходность и равновесие: эмпирические тесты](https://www.jstor.org/stable/1831028), Юджин Ф. Фама и Джеймс Д. Макбет, Journal of Political Economy, 81 (1973), стр. 607–636
- [Ценообразование активов](http://faculty.chicagobooth.edu/john.cochrane/teaching/asset_pricing.htm), Джон Кокрейн, 2001
