# Байесовское машинное обучение: от прогнозирования рецессий до динамической парной торговли

В этой главе мы познакомимся с байесовскими подходами к машинному обучению (ML) и рассмотрим, как их особый взгляд на неопределённость добавляет ценность при разработке и оценке торговых стратегий.

Байесовская статистика позволяет количественно оценивать неопределённость будущих событий и систематически уточнять наши оценки по мере поступления новой информации. Этот динамический подход хорошо адаптируется к изменчивой природе финансовых рынков. Он особенно полезен, когда релевантных данных недостаточно и требуются методы, систематически интегрирующие априорные знания или предположения.

Мы увидим, что байесовские подходы к машинному обучению позволяют получить более глубокое понимание неопределённости статистических метрик, оценок параметров и прогнозов. Области применения варьируются от более детального управления рисками до динамического обновления прогностических моделей, учитывающих изменения рыночной среды. Подход Блэка-Литтермана к распределению активов (см. [Главу 5, Оптимизация портфеля и оценка эффективности](../05_strategy_evaluation)) можно интерпретировать как байесовскую модель. Он вычисляет ожидаемую доходность актива как среднее взвешенное рыночного равновесия и взглядов инвестора, взвешенных по волатильности каждого актива, корреляциям между активами и уверенности в каждом прогнозе.

## Содержание

1. [Как работает байесовское машинное обучение](#как-работает-байесовское-машинное-обучение)
    - [Ссылки](#ссылки)
    * [Как обновлять предположения на основе эмпирических данных](#как-обновлять-предположения-на-основе-эмпирических-данных)
    * [Точный вывод: оценка максимума апостериорной вероятности](#точный-вывод-оценка-максимума-апостериорной-вероятности)
        - [Как упростить вывод: сопряжённые априорные распределения](#как-упростить-вывод-сопряжённые-априорные-распределения)
        - [Пример кода: динамическая оценка вероятностей движения цен активов](#пример-кода-динамическая-оценка-вероятностей-движения-цен-активов)
    * [Детерминированный и стохастический приближённый вывод](#детерминированный-и-стохастический-приближённый-вывод)
2. [Вероятностное программирование с PyMC3](#вероятностное-программирование-с-pymc3)
    * [Байесовское ML с Theano](#байесовское-ml-с-theano)
    * [Рабочий процесс PyMC3](#рабочий-процесс-pymc3)
    * [Пример кода: прогнозирование рецессии с PyMC3](#пример-кода-прогнозирование-рецессии-с-pymc3)
    * [Данные: опережающие индикаторы рецессии](#данные-опережающие-индикаторы-рецессии)
        - [Определение модели: байесовская логистическая регрессия](#определение-модели-байесовская-логистическая-регрессия)
3. [Байесовское ML для трейдинга](#байесовское-ml-для-трейдинга)
    * [Пример кода: байесовский коэффициент Шарпа для сравнения эффективности](#пример-кода-байесовский-коэффициент-шарпа-для-сравнения-эффективности)
    * [Пример кода: байесовская скользящая регрессия для парной торговли](#пример-кода-байесовская-скользящая-регрессия-для-парной-торговли)
    * [Пример кода: модели стохастической волатильности](#пример-кода-модели-стохастической-волатильности)
4. [Ресурсы](#ресурсы)
    * [PyMC3](#pymc3)
    * [Альтернативные библиотеки вероятностного программирования](#альтернативные-библиотеки-вероятностного-программирования)


## Как работает байесовское машинное обучение

Классическая статистика следует частотному (фреквентистскому) подходу, поскольку интерпретирует вероятность как относительную частоту события в долгосрочной перспективе, то есть после наблюдения большого числа испытаний. В контексте вероятностей событие — это комбинация одного или нескольких элементарных исходов эксперимента, например любой из шести равных результатов при броске двух игральных костей или падение цены актива на 10 процентов и более за один день.

Байесовская статистика, напротив, рассматривает вероятность как меру уверенности или убеждённости в наступлении события. Таким образом, байесовская перспектива оставляет больше места для субъективных взглядов и различий во мнениях, чем частотная интерпретация. Это различие наиболее заметно для событий, которые происходят недостаточно часто, чтобы получить объективную меру долгосрочной частоты.

Иными словами, частотная статистика предполагает, что данные являются случайной выборкой из генеральной совокупности, и стремится определить фиксированные параметры, породившие эти данные. Байесовская статистика, в свою очередь, принимает данные как данность и рассматривает параметры как случайные величины с распределением, которое можно вывести из данных. В результате частотные подходы требуют как минимум столько же точек данных, сколько параметров нужно оценить. Байесовские же подходы совместимы с меньшими наборами данных и хорошо подходят для онлайн-обучения на одном образце за раз.

Байесовский взгляд очень полезен для многих реальных событий, которые являются редкими или уникальными, по крайней мере в важных аспектах. Примеры включают исход следующих выборов или вопрос о том, произойдёт ли обвал рынков в течение трёх месяцев. В каждом случае есть как релевантные исторические данные, так и уникальные обстоятельства, которые разворачиваются по мере приближения события.

Сначала мы представим теорему Байеса, которая кристаллизует концепцию обновления убеждений путём объединения априорных предположений с новыми эмпирическими данными, и сравним полученные оценки параметров с их частотными аналогами. Затем мы продемонстрируем два подхода к байесовскому статистическому выводу — сопряжённые априорные распределения и приближённый вывод, — которые дают представление об апостериорном распределении латентных (т.е. ненаблюдаемых) параметров, таких как математическое ожидание:

1. Сопряжённые априорные распределения облегчают процесс обновления, предоставляя решение в замкнутой форме, которое позволяет точно вычислить результат. Однако такие точные аналитические методы доступны не всегда.
2. Приближённый вывод моделирует распределение, получаемое из комбинации предположений и данных, и использует выборки из этого распределения для получения статистических выводов.

#### Ссылки

- [Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
- [Блог Эндрю Гельмана](https://andrewgelman.com/)
- [Блог Томаса Вики](https://twiecki.github.io/)

### Как обновлять предположения на основе эмпирических данных

Теорема, которую преподобный Томас Байес сформулировал более 250 лет назад, использует фундаментальную теорию вероятностей для предписания того, как должны изменяться вероятности или убеждения при поступлении релевантной новой информации, как отражено в цитате Джона Мейнарда Кейнса: «Когда факты меняются, я меняю своё мнение. А что делаете вы, сэр?».

- [Правило Байеса: руководство](https://arbital.com/p/bayes_rule/?l=1zq)
- [Байесовское обновление с непрерывными априорными распределениями](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading13a.pdf), MIT Open Courseware, 18.05 Введение в теорию вероятностей и статистику

### Точный вывод: оценка максимума апостериорной вероятности

Практические применения правила Байеса для точного вычисления апостериорных вероятностей весьма ограничены, поскольку вычисление члена свидетельства в знаменателе представляет значительную сложность.

#### Как упростить вывод: сопряжённые априорные распределения

Априорное распределение является сопряжённым по отношению к функции правдоподобия, когда результирующее апостериорное распределение принадлежит тому же типу, что и априорное, но с другими параметрами. Сопряжённость априорного распределения и функции правдоподобия подразумевает решение в замкнутой форме для апостериорного распределения, что облегчает процесс обновления и устраняет необходимость использования численных методов для аппроксимации апостериорного распределения.

#### Пример кода: динамическая оценка вероятностей движения цен активов

Ноутбук [updating_conjugate_priors](01_updating_conjugate_priors.ipynb) демонстрирует, как использовать сопряжённое априорное распределение для обновления оценок движения цен на основе выборок S&P 500.

### Детерминированный и стохастический приближённый вывод

Для большинства моделей практической значимости будет невозможно аналитически вывести точное апостериорное распределение и вычислить ожидаемые значения латентных параметров.

Хотя для некоторых приложений апостериорное распределение по ненаблюдаемым параметрам будет представлять интерес, чаще всего в первую очередь требуется вычислять математические ожидания, например, для формирования прогнозов. В таких ситуациях мы можем полагаться на приближённый вывод:
- **Стохастические методы**, основанные на сэмплировании методом Марковских цепей Монте-Карло (MCMC), популяризировали использование байесовских методов во многих областях. Они обычно обладают свойством сходимости к точному результату. На практике методы сэмплирования могут быть вычислительно требовательными и часто ограничены задачами малого масштаба.
    - [Концептуальное введение в гамильтоново Монте-Карло](https://arxiv.org/pdf/1701.02434.pdf), Michael Betancourt, 2018
    - [No-U-Turn Sampler: адаптивная установка длины пути в гамильтоновом Монте-Карло](https://arxiv.org/abs/1111.4246), Matthew D. Hoffman, Andrew Gelman, 2011
    - [ML, MAP и байесовский подход — Святая Троица оценки параметров и предсказания данных](https://engineering.purdue.edu/kak/Trinity.pdf)

- **Детерминированные методы**, называемые вариационным выводом или вариационным байесом, основаны на аналитических аппроксимациях апостериорного распределения и могут хорошо масштабироваться для больших приложений. Они делают упрощающие предположения, например, что апостериорное распределение факторизуется определённым образом или имеет конкретную параметрическую форму, такую как гауссово распределение. Следовательно, они не дают точных результатов и могут использоваться как дополнение к методам сэмплирования.
    - [Вариационный вывод: обзор для статистиков](https://arxiv.org/pdf/1601.00670.pdf), David Blei et al, 2018

## Вероятностное программирование с PyMC3

Вероятностное программирование предоставляет язык для описания и подгонки распределений вероятностей, позволяя нам проектировать, кодировать и автоматически оценивать сложные модели. Оно стремится абстрагироваться от части вычислительной и аналитической сложности, чтобы мы могли сосредоточиться на концептуально более простых и интуитивных аспектах байесовского рассуждения и вывода.
Область стала весьма динамичной с появлением новых языков после того, как Uber открыл исходный код Pyro (на основе PyTorch), а Google недавно добавил модуль вероятностей в TensorFlow.

### Байесовское ML с Theano

- [PyMC3](https://docs.pymc.io/) был выпущен в январе 2017 года для добавления методов гамильтонова MC к сэмплеру Метрополиса-Гастингса, используемому в PyMC2 (выпущен в 2012). PyMC3 использует [Theano](http://www.deeplearning.net/software/theano/) в качестве вычислительного бэкенда для динамической C-компиляции и автоматического дифференцирования. Theano — это ориентированная на матрицы библиотека оптимизации с поддержкой GPU, разработанная в Монреальском институте алгоритмов обучения (MILA) Йошуа Бенжио, которая вдохновила TensorFlow. MILA недавно прекратил дальнейшую разработку Theano из-за успеха более новых библиотек глубокого обучения (подробности см. в главе 16).
- [PyMC4](https://github.com/pymc-devs/pymc4), запланированный на 2019 год, будет использовать TensorFlow вместо Theano, предположительно с ограниченным влиянием на API.

### Рабочий процесс PyMC3

PyMC3 стремится к интуитивному и читаемому, но мощному синтаксису, отражающему то, как статистики описывают модели. Процесс моделирования обычно включает следующие три шага:
1) Закодировать вероятностную модель, определив:
    1) Априорные распределения, которые количественно выражают знания и неопределённость относительно латентных переменных
    2) Функцию правдоподобия, которая обусловливает параметры наблюдаемыми данными
2) Проанализировать апостериорное распределение, используя один из вариантов, описанных в предыдущем разделе:
    1) Получить точечную оценку с помощью MAP-вывода
    2) Произвести выборку из апостериорного распределения с помощью методов MCMC
    3) Аппроксимировать апостериорное распределение с помощью вариационного байеса
3) Проверить модель с помощью различных диагностических инструментов
4) Сгенерировать прогнозы

- [Документация](https://docs.pymc.io/)
- [Вероятностное программирование на Python с использованием PyMC](https://arxiv.org/abs/1507.08050), Salvatier et al 2015
- [Theano: фреймворк Python для быстрого вычисления математических выражений](https://pdfs.semanticscholar.org/6b57/0069f14c7588e066f7138e1f21af59d62e61.pdf), Al-Rfou et al, 2016
- [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)
- [Плохие трассировки, или Не используйте Метрополис](https://colindcarroll.com/2018/01/01/bad-traces-or-dont-use-metropolis/)
- PyMC 4 на [GitHub](https://github.com/pymc-devs/pymc4) с руководством по дизайну и примерами использования.

### Пример кода: прогнозирование рецессии с PyMC3

Ноутбук [pymc3_workflow](02_pymc3_workflow.ipynb) иллюстрирует различные аспекты рабочего процесса PyMC3 на примере простой логистической регрессии для моделирования предсказания рецессии.

### Данные: опережающие индикаторы рецессии

Мы будем использовать небольшой и простой набор данных, чтобы сосредоточиться на рабочем процессе. Мы используем службу экономических данных Федерального резерва (FRED) (см. Главу 2) для загрузки дат рецессий в США, определённых Национальным бюро экономических исследований. Мы также получаем четыре переменные, которые обычно используются для прогнозирования начала рецессии (Kelley 2019) и доступны через FRED, а именно:
- Долгосрочный спред кривой доходности казначейских облигаций, определяемый как разница между десятилетней и трёхмесячной доходностью казначейских облигаций.
- Индикатор потребительских настроений Мичиганского университета
- Индекс национальных финансовых условий (NFCI), и
- Субиндекс нефинансового левериджа NFCI.

#### Определение модели: байесовская логистическая регрессия

Как обсуждалось в главе [Линейные модели](../07_linear_models), логистическая регрессия оценивает линейную зависимость между набором признаков и бинарным исходом, опосредованную сигмоидной функцией для обеспечения того, чтобы модель выдавала вероятности. Частотный подход давал точечные оценки параметров, измеряющих влияние каждого признака на вероятность принадлежности точки данных к положительному классу, с доверительными интервалами, основанными на предположениях о распределении параметров.

Байесовская логистическая регрессия, напротив, оценивает само апостериорное распределение по параметрам. Апостериорное распределение позволяет получить более робастные оценки так называемого байесовского доверительного интервала для каждого параметра с преимуществом большей прозрачности относительно неопределённости модели.

Ноутбук [pymc3_workflow](02_pymc3_workflow.ipynb) демонстрирует рабочий процесс PyMC3, включая:
- MAP-вывод
- Оценку методом Марковских цепей Монте-Карло
    - Метрополис-Гастингс
    - NUTS Sampler
- Вариационный вывод
- Диагностику модели
    - Графики энергии и леса
    - Апостериорные предиктивные проверки (PPD), и
    - Доверительные интервалы (CI)
- Предсказание
- Анимацию MCMC-сэмплера

## Байесовское ML для трейдинга

Теперь, когда мы знакомы с байесовским подходом к ML и вероятностным программированием с PyMC3, давайте рассмотрим несколько релевантных приложений, связанных с трейдингом, а именно:
- моделирование коэффициента Шарпа как вероятностной модели для более глубокого сравнения эффективности
- вычисление коэффициентов хеджирования для парной торговли с использованием байесовской линейной регрессии
- анализ линейных моделей временных рядов с байесовской точки зрения

### Пример кода: байесовский коэффициент Шарпа для сравнения эффективности

Ноутбук [bayesian_sharpe_ratio](03_bayesian_sharpe_ratio.ipynb) иллюстрирует, как определить коэффициент Шарпа (SR) как вероятностную модель с использованием PyMC3 и как сравнивать его апостериорные распределения для различных рядов доходности.

Байесовская оценка для двух рядов предлагает очень богатые выводы, поскольку предоставляет полные распределения достоверных значений для размера эффекта, средних SR групп и их разности, а также стандартных отклонений и их разности. Реализация на Python принадлежит Томасу Вики и была вдохновлена пакетом R BEST (Meredith and Kruschke 2018), см. «Ресурсы» ниже.

Релевантные случаи использования байесовского SR включают анализ различий между альтернативными стратегиями или между доходностью стратегии на обучающей выборке относительно её доходности на тестовой выборке (подробности см. в ноутбуке bayesian_sharpe_ratio). Байесовский коэффициент Шарпа также является частью байесовского отчёта pyfolio.

### Пример кода: байесовская скользящая регрессия для парной торговли

В [предыдущей главе](../09_time_series_models) парная торговля была представлена как популярная торговая стратегия, которая опирается на **коинтеграцию** двух или более активов. Имея такие активы, нам нужно оценить коэффициент хеджирования, чтобы определить относительную величину длинных и коротких позиций. Базовый подход использует линейную регрессию.

Ноутбук [rolling_regression](04_rolling_regression.ipynb) иллюстрирует, как байесовская линейная регрессия отслеживает изменения в отношениях между двумя активами с течением времени. Он следует примеру Томаса Вики (см. «Ресурсы» ниже).

### Пример кода: модели стохастической волатильности

Как обсуждалось в главе [Модели временных рядов](../09_time_series_models), цены активов имеют изменяющуюся во времени волатильность. В некоторые периоды доходности сильно варьируются, тогда как в другие — очень стабильны.

Модели стохастической волатильности моделируют это с помощью латентной переменной волатильности, моделируемой как стохастический процесс. No-U-Turn Sampler был представлен с использованием такой модели, и ноутбук [stochastic_volatility](05_stochastic_volatility.ipynb) иллюстрирует этот случай использования.

## Ресурсы

### PyMC3

Томас Вики, один из основных авторов PyMC3, который также возглавляет Data Science в Quantopian, создал несколько примеров, на которых основаны и которые развивают следующие разделы. Документация PyMC3 содержит много дополнительных руководств.

- [Учебные материалы](https://docs.pymc.io/nb_tutorials/index.html) PyMC3
- [Решение проблемы слабых предположений наивных байесовских текстовых классификаторов](http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf), Rennie, et al, MIT SAIL, 2003
- [О дискриминативных и генеративных классификаторах: сравнение логистической регрессии и наивного Байеса](https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf), Jordan, Ng, 2002
- [Байесовская оценка превосходит t-критерий](http://www.indiana.edu/~kruschke/BEST/BEST.pdf), John K. Kruschke, Journal of Experimental Psychology, 2012
- [Автоматическое дифференцирование вариационного вывода](https://arxiv.org/pdf/1603.00788.pdf)

### Альтернативные библиотеки вероятностного программирования
- [Вероятностное программирование](http://www.probabilistic-programming.org/wiki/Home) — репозиторий сообщества со ссылками на статьи и программное обеспечение
- [Stan](https://mc-stan.org/)
- [Edward](http://edwardlib.org/)
- [TensorFlow Probability](https://github.com/tensorflow/probability)
- [Pyro](http://pyro.ai/)
