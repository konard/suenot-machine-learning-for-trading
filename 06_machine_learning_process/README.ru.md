# Рабочий процесс машинного обучения

Эта глава открывает вторую часть книги, где мы демонстрируем, как можно использовать различные модели машинного обучения (МО) с учителем и без учителя для трейдинга. Мы объясним допущения и области применения каждой модели, а затем продемонстрируем практические приложения с использованием различных библиотек Python. Категории моделей, которые мы рассмотрим в частях 2-4:

- Линейные модели для регрессии и классификации кросс-секционных, временных рядов и панельных данных
- Обобщённые аддитивные модели, включая нелинейные модели на основе деревьев, такие как деревья решений
- Ансамблевые модели, включая случайный лес и градиентный бустинг
- Методы понижения размерности и кластеризации без учителя (линейные и нелинейные)
- Модели нейронных сетей, включая рекуррентные и свёрточные архитектуры
- Модели обучения с подкреплением

Мы будем применять эти модели к рыночным, фундаментальным и альтернативным источникам данных, представленным в первой части книги. Мы будем опираться на уже изученный материал, демонстрируя, как встроить эти модели в торговую стратегию, которая преобразует сигналы модели в сделки, как оптимизировать портфель и как оценивать эффективность стратегии.

Многие из этих моделей и их применений имеют общие аспекты. В этой главе рассматриваются эти общие аспекты, чтобы в последующих главах мы могли сосредоточиться на специфике каждой модели. К ним относятся главная цель — изучение функциональной зависимости на основе данных путём оптимизации целевой функции или функции потерь. Также сюда входят тесно связанные методы измерения производительности модели.

Мы различаем обучение без учителя и с учителем и описываем варианты использования для алгоритмической торговли. Мы сравниваем задачи регрессии и классификации с учителем, использование обучения с учителем для статистического вывода о взаимосвязях между входными и выходными данными с его использованием для прогнозирования будущих результатов. Мы также показываем, как ошибки прогнозирования возникают из-за смещения или дисперсии модели, или из-за высокого соотношения шума к сигналу в данных. Что наиболее важно, мы представляем методы диагностики источников ошибок, таких как переобучение, и улучшения производительности модели.

Если вы уже хорошо знакомы с машинным обучением, можете пропустить эту главу и сразу перейти к изучению того, как использовать модели МО для создания и комбинирования альфа-факторов в алгоритмической торговой стратегии.

## Содержание

1. [Как работает машинное обучение на данных](#как-работает-машинное-обучение-на-данных)
    * [Ключевая задача: Найти правильный алгоритм для данной задачи](#ключевая-задача-найти-правильный-алгоритм-для-данной-задачи)
    * [Обучение с учителем: обучение задаче на примерах](#обучение-с-учителем-обучение-задаче-на-примерах)
    * [Обучение без учителя: Исследование данных для выявления полезных закономерностей](#обучение-без-учителя-исследование-данных-для-выявления-полезных-закономерностей)
        - [Применение в торговых стратегиях: От управления рисками до обработки текста](#применение-в-торговых-стратегиях-от-управления-рисками-до-обработки-текста)
    * [Обучение с подкреплением: Обучение через действие, шаг за шагом](#обучение-с-подкреплением-обучение-через-действие-шаг-за-шагом)
2. [Рабочий процесс машинного обучения](#рабочий-процесс-машинного-обучения-1)
    * [Пример кода: Рабочий процесс МО с методом K-ближайших соседей](#пример-кода-рабочий-процесс-мо-с-методом-k-ближайших-соседей)
3. [Постановка задачи: цели и метрики](#постановка-задачи-цели-и-метрики)
4. [Сбор и подготовка данных](#сбор-и-подготовка-данных)
5. [Как исследовать, извлекать и конструировать признаки](#как-исследовать-извлекать-и-конструировать-признаки)
    * [Пример кода: Взаимная информация](#пример-кода-взаимная-информация)
6. [Выбор алгоритма МО](#выбор-алгоритма-мо)
7. [Проектирование и настройка модели](#проектирование-и-настройка-модели)
    * [Пример кода: Компромисс смещения и дисперсии](#пример-кода-компромисс-смещения-и-дисперсии)
8. [Как использовать кросс-валидацию для выбора модели](#как-использовать-кросс-валидацию-для-выбора-модели)
    * [Пример кода: Реализация кросс-валидации в Python](#пример-кода-реализация-кросс-валидации-в-python)
9. [Настройка параметров с помощью scikit-learn](#настройка-параметров-с-помощью-scikit-learn)
    * [Пример кода: Кривые обучения и валидации с yellowbricks](#пример-кода-кривые-обучения-и-валидации-с-yellowbricks)
    * [Пример кода: Настройка параметров с GridSearchCV и pipeline](#пример-кода-настройка-параметров-с-gridsearchcv-и-pipeline)
10. [Особенности кросс-валидации в финансах](#особенности-кросс-валидации-в-финансах)
    * [Очистка, эмбарго и комбинаторная кросс-валидация](#очистка-эмбарго-и-комбинаторная-кросс-валидация)


## Как работает машинное обучение на данных

Многие определения машинного обучения связаны с автоматическим обнаружением значимых закономерностей в данных. Два известных примера:
- Пионер ИИ Артур Сэмюэль определил МО в 1959 году как подраздел компьютерных наук, который даёт компьютерам способность обучаться без явного программирования.
- Том Митчелл, один из нынешних лидеров в этой области, более точно определил корректно поставленную задачу обучения в 1998 году: компьютерная программа учится на опыте в отношении задачи и меры производительности, если производительность выполнения задачи улучшается с опытом (Mitchell, 1997).

Опыт представляется алгоритму в форме обучающих данных. Принципиальное отличие от предыдущих попыток создания машин, решающих задачи, заключается в том, что правила, которые алгоритм использует для принятия решений, извлекаются из данных, а не программируются людьми, как это было, например, в экспертных системах, популярных в 1980-х годах.

Рекомендуемые учебники, охватывающие широкий спектр алгоритмов и общих приложений:
- [An Introduction to Statistical Learning](http://faculty.marshall.usc.edu/gareth-james/ISL/), James et al (2013)
- [The Elements of Statistical Learning: Data Mining, Inference, and Prediction](https://web.stanford.edu/~hastie/ElemStatLearn/), Hastie, Tibshirani, and Friedman (2009)
- [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf), Bishop (2006)
- [Machine Learning](http://www.cs.cmu.edu/~tom/mlbook.html), Mitchell (1997)

### Ключевая задача: Найти правильный алгоритм для данной задачи

Ключевая задача автоматического обучения — выявить закономерности в обучающих данных, которые остаются значимыми при обобщении обучения модели на новые данные. Существует большое количество потенциальных закономерностей, которые модель может выявить, в то время как обучающие данные представляют лишь выборку из более широкого набора явлений, с которыми алгоритм может столкнуться при выполнении задачи в будущем.

### Обучение с учителем: обучение задаче на примерах

Обучение с учителем — наиболее часто используемый тип машинного обучения. Большую часть глав этой книги мы посвятим приложениям в этой категории. Термин «с учителем» подразумевает наличие целевой переменной, которая направляет процесс обучения — то есть учит алгоритм правильному решению поставленной задачи. Обучение с учителем направлено на выявление функциональной зависимости между входом и выходом на основе отдельных примеров, отражающих эту зависимость, и применение полученных знаний для формирования обоснованных выводов о новых данных.

### Обучение без учителя: Исследование данных для выявления полезных закономерностей

При решении задачи обучения без учителя мы наблюдаем только признаки и не имеем измерений результата. Вместо прогнозирования будущих результатов или выявления взаимосвязей между переменными, алгоритмы без учителя направлены на выявление структуры во входных данных, которая позволяет по-новому представить содержащуюся в них информацию.

#### Применение в торговых стратегиях: От управления рисками до обработки текста

Существует множество применений обучения без учителя в торговле, которые мы рассмотрим в следующих главах:
- Группировка ценных бумаг со схожими характеристиками риска и доходности (см. [иерархический паритет рисков в Главе 13](../13_unsupervised_learning/04_hierarchical_risk_parity))
- Выявление небольшого числа факторов риска, определяющих поведение гораздо большего числа ценных бумаг, с использованием [анализа главных компонент](../13_unsupervised_learning/01_linear_dimensionality_reduction)) или автоэнкодеров ([Глава 20](../20_autoencoders_for_conditional_risk_factors))
- Выявление скрытых тем в корпусе документов (например, транскриптов телеконференций по результатам деятельности), которые представляют наиболее важные аспекты этих документов ([Глава 15](../15_topic_modeling))

### Обучение с подкреплением: Обучение через действие, шаг за шагом

Обучение с подкреплением (RL) — третий тип машинного обучения. Оно сосредоточено на агенте, который должен выбирать действие на каждом временном шаге на основе информации, предоставляемой средой. Агентом может быть беспилотный автомобиль, программа, играющая в настольную или видеоигру, или торговая стратегия, работающая на определённом рынке ценных бумаг.

Отличное введение можно найти в [Sutton and Barto](http://www.incompleteideas.net/book/the-book-2nd.html), 2018.

## Рабочий процесс машинного обучения

Разработка решения на основе МО требует систематического подхода для максимизации шансов на успех при эффективном продвижении. Также важно сделать процесс прозрачным и воспроизводимым для облегчения сотрудничества, поддержки и последующих улучшений.

Процесс итеративен на всём протяжении, и усилия на разных этапах будут варьироваться в зависимости от проекта. Тем не менее, этот процесс обычно должен включать следующие шаги:

1. Постановка задачи, определение целевой метрики и критериев успеха
2. Сбор, очистка и валидация данных
3. Понимание данных и создание информативных признаков
4. Выбор одного или нескольких алгоритмов машинного обучения, подходящих для ваших данных
5. Обучение, тестирование и настройка моделей
6. Использование модели для решения исходной задачи

### Пример кода: Рабочий процесс МО с методом K-ближайших соседей

Ноутбук [machine_learning_workflow](01_machine_learning_workflow.ipynb) содержит несколько примеров, иллюстрирующих рабочий процесс машинного обучения на простом наборе данных о ценах на жильё.

- sklearn [Документация](http://scikit-learn.org/stable/documentation.html)
- Метод k-ближайших соседей [руководство](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn) и [визуализация](http://vision.stanford.edu/teaching/cs231n-demos/knn/)

## Постановка задачи: цели и метрики

Отправной точкой любого упражнения по машинному обучению является конечный вариант использования, который оно призвано решить. Иногда целью будет статистический вывод для выявления связи между переменными или даже причинно-следственной связи. Однако чаще всего целью будет непосредственное прогнозирование результата для получения торгового сигнала.

## Сбор и подготовка данных

Мы рассмотрели получение рыночных и фундаментальных данных в [Главе 2](../02_market_and_fundamental_data), а альтернативных данных — в [Главе 3](../03_alternative_data). Мы продолжим работать с различными примерами этих источников, демонстрируя применение различных моделей в последующих главах.

## Как исследовать, извлекать и конструировать признаки

Понимание распределения отдельных переменных и взаимосвязей между результатами и признаками является основой для выбора подходящего алгоритма. Обычно это начинается с визуализаций, таких как диаграммы рассеяния, как показано в сопроводительном ноутбуке (и на следующем изображении), но также включает численные оценки, начиная от линейных метрик, таких как корреляция, до нелинейных статистик, таких как коэффициент ранговой корреляции Спирмена, с которым мы познакомились при введении информационного коэффициента. Сюда также входят теоретико-информационные меры, такие как взаимная информация.

### Пример кода: Взаимная информация

Ноутбук [mutual_information](02_mutual_information.ipynb) применяет теорию информации к финансовым данным, созданным в ноутбуке [feature_engineering](../04_alpha_factor_research/00_data/feature_engineering.ipynb), в главе [Альфа-факторы – Исследование и оценка](../04_alpha_factor_research).

## Выбор алгоритма МО

Оставшаяся часть книги познакомит с несколькими семействами моделей, от линейных моделей, которые делают довольно сильные допущения о природе функциональной связи между входными и выходными переменными, до глубоких нейронных сетей, которые делают очень мало допущений.

## Проектирование и настройка модели

Процесс МО включает шаги по диагностике и управлению сложностью модели на основе оценок ошибки обобщения модели. Несмещённая оценка требует статистически обоснованной и эффективной процедуры, а также метрик ошибок, соответствующих типу выходной переменной, который также определяет, имеем ли мы дело с задачей регрессии, классификации или ранжирования.

### Пример кода: Компромисс смещения и дисперсии

Ошибки, которые модель МО делает при прогнозировании результатов для новых входных данных, можно разбить на устранимую и неустранимую части. Неустранимая часть обусловлена случайными вариациями (шумом) в данных, которые не измеряются, например, релевантными, но отсутствующими переменными или естественными вариациями.

Ноутбук [bias_variance](03_bias_variance.ipynb) демонстрирует переобучение путём аппроксимации функции косинуса всё более сложными полиномами и измерения ошибки на обучающей выборке. Он создаёт 10 случайных выборок с добавлением некоторого шума (n = 30) для обучения полинома различной сложности. Каждый раз модель предсказывает новые точки данных, и мы фиксируем среднеквадратичную ошибку для этих предсказаний, а также стандартное отклонение этих ошибок. Далее демонстрируется влияние переобучения и недообучения при попытке изучить аппроксимацию функции косинуса рядом Тейлора девятой степени с добавлением некоторого шума. На следующей диаграмме мы создаём случайные выборки истинной функции и подбираем полиномы с недостаточной, избыточной и приблизительно правильной степенью гибкости.

## Как использовать кросс-валидацию для выбора модели

Когда для вашей задачи доступно несколько моделей-кандидатов (то есть алгоритмов), выбор одной из них называется задачей выбора модели. Выбор модели направлен на определение модели, которая даст наименьшую ошибку прогнозирования на новых данных.

### Пример кода: Реализация кросс-валидации в Python

Скрипт [cross_validation](04_cross_validation.py) иллюстрирует различные варианты разделения данных на обучающую и тестовую выборки, показывая, как индексы тестового набора данных с десятью наблюдениями назначаются обучающей и тестовой выборкам.

## Настройка параметров с помощью scikit-learn

Выбор модели обычно включает многократную кросс-валидацию производительности на отложенной выборке для моделей с использованием различных алгоритмов (например, линейная регрессия и случайный лес) или различных конфигураций. Различные конфигурации могут включать изменения гиперпараметров или включение/исключение различных переменных.

### Пример кода: Кривые обучения и валидации с yellowbricks

Ноутбук [machine_learning_workflow](01_machine_learning_workflow.ipynb) демонстрирует использование кривых обучения и валидации и иллюстрирует применение различных методов выбора модели.

- Yellowbrick: Визуализация машинного обучения [документация](http://www.scikit-yb.org/en/latest/)

### Пример кода: Настройка параметров с GridSearchCV и pipeline

Поскольку настройка гиперпараметров является ключевым компонентом рабочего процесса машинного обучения, существуют инструменты для автоматизации этого процесса. Библиотека sklearn включает интерфейс GridSearchCV, который выполняет кросс-валидацию всех комбинаций параметров параллельно, сохраняет результаты и автоматически обучает модель с использованием настроек параметров, показавших лучшие результаты во время кросс-валидации, на полном наборе данных.

На практике обучающие и валидационные выборки часто требуют некоторой обработки перед кросс-валидацией. Scikit-learn предлагает Pipeline для автоматизации любых необходимых шагов обработки признаков в автоматизированной настройке гиперпараметров, осуществляемой GridSearchCV.

Примеры реализации см. в ноутбуке machine_learning_workflow.ipynb.

Ноутбук [machine_learning_workflow](01_machine_learning_workflow.ipynb) также демонстрирует использование этих инструментов.

## Особенности кросс-валидации в финансах

Ключевое допущение для методов кросс-валидации, рассмотренных выше, — это независимое и одинаковое (iid) распределение выборок, доступных для обучения.
Для финансовых данных это часто не так. Напротив, финансовые данные не являются ни независимыми, ни одинаково распределёнными из-за автокорреляции и изменяющегося во времени стандартного отклонения, также известного как гетероскедастичность.

### Очистка, эмбарго и комбинаторная кросс-валидация

Для финансовых данных метки часто получаются из перекрывающихся точек данных, поскольку доходности вычисляются из цен за несколько периодов. В контексте торговых стратегий результаты прогноза модели, которые могут подразумевать открытие позиции по активу, могут стать известны только позже, когда это решение будет оценено — например, когда позиция будет закрыта.

Возникающие риски включают утечку информации из тестовой выборки в обучающую, что, вероятно, приведёт к искусственно завышенным показателям производительности. Это необходимо решать, обеспечивая, чтобы все данные были «на момент времени» — то есть действительно доступны и известны в момент их использования в качестве входных данных для модели. Несколько методов были предложены Маркосом Лопесом де Прадо в книге [Advances in Financial Machine Learning](https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089) для решения этих проблем финансовых данных при кросс-валидации:

- Очистка (Purging): Удаление обучающих точек данных, для которых оценка происходит после прогноза точки данных «на момент времени» в валидационной выборке, чтобы избежать смещения из-за заглядывания в будущее.
- Эмбарго (Embargoing): Дополнительное удаление обучающих образцов, следующих за тестовым периодом.
