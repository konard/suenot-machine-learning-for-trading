# Chapter 54: Reformer - LSH Attention

## Описание

Locality-Sensitive Hashing для эффективного attention с O(n log n) сложностью.

## Техническое задание

### Цели
1. Изучить теоретические основы метода
2. Реализовать базовую версию на Python
3. Создать оптимизированную версию на Rust
4. Протестировать на финансовых данных
5. Провести бэктестинг торговой стратегии

### Ключевые компоненты
- Теоретическое описание метода
- Python реализация с PyTorch
- Rust реализация для production
- Jupyter notebooks с примерами
- Бэктестинг framework

### Метрики
- Accuracy / F1-score для классификации
- MSE / MAE для регрессии
- Sharpe Ratio / Sortino Ratio для стратегий
- Maximum Drawdown
- Сравнение с baseline моделями

## Научные работы

1. **Reformer: The Efficient Transformer**
   - URL: https://arxiv.org/abs/2001.04451
   - Год: 2020

## Данные
- Yahoo Finance / yfinance
- Binance API для криптовалют
- LOBSTER для order book data
- Kaggle финансовые датасеты

## Реализация

### Python
- PyTorch / TensorFlow
- NumPy, Pandas
- scikit-learn
- Backtrader / Zipline

### Rust
- ndarray
- polars
- burn / candle

## Структура
```
54_reformer_lsh_attention/
├── README.specify.md
├── README.md
├── docs/
│   └── ru/
│       └── theory.md
├── python/
│   ├── model.py
│   ├── train.py
│   ├── backtest.py
│   └── notebooks/
│       └── example.ipynb
└── rust/
    └── src/
        └── lib.rs
```
