# Сверточные нейронные сети: временные ряды как изображения

В этой главе мы представляем первую специализированную архитектуру глубокого обучения, которую рассмотрим в части 4. Глубокие сверточные нейронные сети (Deep Convolutional Neural Networks), также известные как ConvNets или CNN, обеспечили сверхчеловеческую производительность в классификации изображений, видео, речи и аудио. Рекуррентные сети, тема следующей главы, показали исключительные результаты на последовательных данных, таких как текст и речь.

CNN названы в честь операции линейной алгебры, называемой сверткой, которая заменяет общее матричное умножение, типичное для сетей прямого распространения (обсуждаемых в предыдущей главе о глубоком обучении), как минимум в одном из их слоев. Мы обсудим, как работают свертки и почему они особенно полезны для данных с определенной регулярной структурой, таких как изображения или временные ряды.

Исследования архитектур CNN развиваются очень быстро, и новые архитектуры, улучшающие эталонную производительность, продолжают появляться. Мы опишем набор строительных блоков, которые постоянно появляются в успешных приложениях, и продемонстрируем их применение к данным изображений и финансовым временным рядам. Мы также продемонстрируем, как трансферное обучение может ускорить обучение за счет использования предварительно обученных весов для некоторых слоев CNN.

## Содержание

1. [Как CNN обучаются моделировать данные сеточной структуры](#как-cnn-обучаются-моделировать-данные-сеточной-структуры)
    * [Пример кода: от ручного кодирования к обучению и синтезу фильтров из данных](#пример-кода-от-ручного-кодирования-к-обучению-и-синтезу-фильтров-из-данных)
    * [Как работают ключевые элементы сверточного слоя](#как-работают-ключевые-элементы-сверточного-слоя)
    * [Задачи компьютерного зрения](#задачи-компьютерного-зрения)
    * [Эволюция архитектур CNN: ключевые инновации](#эволюция-архитектур-cnn-ключевые-инновации)
2. [CNN для изображений: от спутниковых данных до обнаружения объектов](#cnn-для-изображений-от-спутниковых-данных-до-обнаружения-объектов)
    * [Пример кода: LeNet5 - первая CNN с промышленным применением](#пример-кода-lenet5---первая-cnn-с-промышленным-применением)
    * [Пример кода: AlexNet - возрождение исследований глубокого обучения](#пример-кода-alexnet---возрождение-исследований-глубокого-обучения)
    * [Пример кода: трансферное обучение с VGG16 на практике](#пример-кода-трансферное-обучение-с-vgg16-на-практике)
        - [Как извлечь признаки узкого места](#как-извлечь-признаки-узкого-места)
        - [Как дообучить предварительно обученную модель](#как-дообучить-предварительно-обученную-модель)
    * [Пример кода: определение типа землепользования по спутниковым снимкам с использованием трансферного обучения](#пример-кода-определение-типа-землепользования-по-спутниковым-снимкам)
    * [Пример кода: обнаружение объектов на практике с номерами домов Google Street View](#пример-кода-обнаружение-объектов-с-номерами-домов-google-street-view)
        - [Предварительная обработка исходных изображений](#предварительная-обработка-исходных-изображений)
        - [Трансферное обучение с пользовательским финальным слоем для множественных выходов](#трансферное-обучение-с-пользовательским-финальным-слоем)
3. [CNN для данных временных рядов: прогнозирование доходности акций](#cnn-для-данных-временных-рядов-прогнозирование-доходности-акций)
    * [Пример кода: построение авторегрессионной CNN с 1D-свертками](#пример-кода-построение-авторегрессионной-cnn-с-1d-свертками)
    * [Пример кода: CNN-TA - кластеризация финансовых временных рядов в 2D-формате изображений](#пример-кода-cnn-ta---кластеризация-финансовых-временных-рядов)
        - [Создание 2D временных рядов финансовых индикаторов](#создание-2d-временных-рядов-финансовых-индикаторов)
        - [Выбор и кластеризация наиболее релевантных признаков](#выбор-и-кластеризация-наиболее-релевантных-признаков)
        - [Создание и обучение сверточной нейронной сети](#создание-и-обучение-сверточной-нейронной-сети)
        - [Бэктестинг long-short торговой стратегии](#бэктестинг-long-short-торговой-стратегии)

## Как CNN обучаются моделировать данные сеточной структуры

CNN концептуально схожи с нейросетями прямого распространения (feedforward NN), которые мы рассмотрели в предыдущей главе. Они состоят из блоков, содержащих параметры, называемые весами и смещениями, и процесс обучения настраивает эти параметры для оптимизации выхода сети при заданном входе. Каждый блок применяет свои параметры к линейной операции над входными данными или активациями, полученными от других блоков, за которой, возможно, следует нелинейное преобразование.

CNN отличаются тем, что они кодируют предположение о том, что входные данные имеют структуру, наиболее часто встречающуюся в данных изображений, где пиксели образуют двумерную сетку, обычно с несколькими каналами для представления компонентов цветового сигнала, таких как красный, зеленый и синий каналы цветовой модели RGB.

Наиболее важным элементом для кодирования предположения о сеточной топологии является операция свертки, давшая CNN их название, в сочетании с пулингом. Мы увидим, что конкретные предположения о функциональной связи между входными и выходными данными означают, что CNN требуют гораздо меньше параметров и вычисляются более эффективно.

### Пример кода: от ручного кодирования к обучению и синтезу фильтров из данных

Для данных изображений эта локальная структура традиционно мотивировала разработку вручную закодированных фильтров, которые извлекают такие паттерны для использования в качестве признаков в моделях машинного обучения.
- Ноутбук [filter_example](01_filter_example.ipynb) иллюстрирует, как использовать вручную закодированные фильтры в сверточной сети и визуализировать результирующее преобразование изображения.
- См. [Interpretability of Deep Learning Models with Tensorflow 2.0](https://www.sicara.ai/blog/2019-08-28-interpretability-deep-learning-tensorflow) для примера визуализации паттернов, изученных фильтрами CNN.

### Как работают ключевые элементы сверточного слоя

Полносвязные нейросети прямого распространения не делают предположений о топологии или локальной структуре входных данных, так что произвольная перестановка признаков не влияет на результат обучения.

Однако для многих источников данных локальная структура весьма значима. Примеры включают автокорреляцию во временных рядах или пространственную корреляцию между значениями пикселей из-за общих паттернов, таких как края или углы. Для данных изображений эта локальная структура традиционно мотивировала разработку вручную закодированных методов фильтрации, которые извлекают локальные паттерны для использования в качестве признаков в моделях машинного обучения.

- [Deep Learning](http://www.deeplearningbook.org/contents/convnets.html), Глава 9, Сверточные сети, Ian Goodfellow и др., MIT Press, 2016
- [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/syllabus.html), Курс глубокого обучения Стэнфорда. Полезен для построения фундамента, с увлекательными лекциями и наглядными заданиями.
- [Convolutional Neural Networks (CNNs / ConvNets)](http://cs231n.github.io/convolutional-networks/#conv), Модуль 2 в CS231n, Конспекты лекций Andrew Karpathy, Стэнфорд, 2016
- [ImageNet Large Scale Visual Recognition Challenge (ILSVRC)](http://www.image-net.org/challenges/LSVRC/)
- [Convnet Benchmarks](https://github.com/soumith/convnet-benchmarks), Бенчмаркинг всех публично доступных реализаций convnets
- [ConvNetJS](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html), Демо ConvNetJS CIFAR-10 в браузере от Andrew Karpathy
- [An Interactive Node-Link Visualization of Convolutional Neural Networks](http://scs.ryerson.ca/~aharley/vis/), Интерактивная визуализация CNN
- [GradientBased Learning Applied to Document Recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf), Yann LeCun, Leon Bottou, Yoshua Bengio и Patrick, IEEE, 1998
- [Understanding Convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/), Christopher Olah, 2014
- [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122), Fisher Yu, Vladlen Koltun, ICLR 2016

### Задачи компьютерного зрения

Классификация изображений - это фундаментальная задача компьютерного зрения, которая требует присвоения метки изображению на основе определенных объектов, которые оно содержит. Многие практические приложения, включая инвестиционные и торговые стратегии, требуют дополнительной информации.
- Задача обнаружения объектов требует не только идентификации, но и пространственного расположения всех интересующих объектов, обычно с использованием ограничивающих рамок. Было разработано несколько алгоритмов для преодоления неэффективности подходов грубой силы со скользящим окном, включая методы предложения регионов (R-CNN) и алгоритм обнаружения объектов в реальном времени You Only Look Once (YOLO) (см. ссылки на GitHub).
- Задача сегментации объектов идет на шаг дальше и требует метки класса и контура каждого объекта на входном изображении. Это может быть полезно для подсчета объектов на изображении и оценки уровня активности.
- Семантическая сегментация, также называемая разбором сцены, делает плотные прогнозы для присвоения метки класса каждому пикселю изображения. В результате изображение делится на семантические области, и каждый пиксель присваивается своему охватывающему объекту или области.

- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/), Обнаружение объектов в реальном времени You Only Look Once
- [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf), Girshick и др., Беркли, arxiv 2014
- [Playing around with RCNN](https://cs.stanford.edu/people/karpathy/rcnn/), Andrew Karpathy, Стэнфорд
- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO — Object Detection Algorithms](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e), Rohith Ghandi, 2018

### Эволюция архитектур CNN: ключевые инновации

Несколько архитектур CNN раздвинули границы производительности за последние два десятилетия, внедрив важные инновации. Рост прогностической производительности резко ускорился с появлением больших данных в форме ImageNet (Fei-Fei 2015) с 14 миллионами изображений, присвоенных 20 000 классов людьми через Amazon Mechanical Turk. ImageNet Large Scale Visual Recognition Challenge (ILSVRC) стал фокусной точкой прогресса CNN вокруг несколько меньшего набора из 1,2 миллиона изображений из 1000 классов.

- [Fully Convolutional Networks for Semantic Segmentation](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf), Long и др., Беркли
- [Mask R-CNN](https://arxiv.org/abs/1703.06870), Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick, arxiv, 2017
- [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf), Olaf Ronneberger, Philipp Fischer и Thomas Brox, arxiv 2015
- [U-Net Tutorial](http://deeplearning.net/tutorial/unet.html)
- [Very Deep Convolutional Networks for Large-Scale Visual Recognition](http://www.robots.ox.ac.uk/~vgg/research/very_deep/), Karen Simonyan и Andrew Zisserman о VGG16, победившей в конкурсе ImageNet ILSVRC-2014
- [Benchmarks for popular CNN models](https://github.com/jcjohnson/cnn-benchmarks)
- [Analysis of deep neural networks](https://medium.com/@culurciello/analysis-of-deep-neural-networks-dcf398e71aae), Alfredo Canziani и др., 2018
- [LeNet-5 Demos](http://yann.lecun.com/exdb/lenet/index.html)
- [Neural Network Architectures](https://towardsdatascience.com/neural-network-architectures-156e5bad51ba)
- [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf), Kaiming He и др., Microsoft Research, 2015
- [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567), Christian Szegedy и др., arxiv 2015
- [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261), Christian Szegedy и др., arxiv, 2016
- [Network In Network](https://arxiv.org/pdf/1312.4400v3.pdf), Min Lin и др., arxiv 2014
- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167), Sergey Ioffe, Christian Szegedy, arxiv 2015
- [An Overview of ResNet and its Variants](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035), Vincent Fung, 2017

## CNN для изображений: от спутниковых данных до обнаружения объектов

В этом разделе демонстрируется решение ключевых задач компьютерного зрения, таких как классификация изображений и обнаружение объектов. Как упоминалось во введении и в Главе 3 об альтернативных данных, данные изображений могут информировать торговую стратегию, предоставляя подсказки о будущих трендах, изменяющихся фундаментальных показателях или конкретных событиях, релевантных для целевого класса активов или инвестиционной вселенной. Популярные примеры включают использование спутниковых снимков для получения информации о предложении сельскохозяйственных товаров, потребительской и экономической активности или состоянии производственных цепочек поставок или сырья. Конкретные задачи могут включать, например:
- Классификация изображений: определить, расширяются ли обрабатываемые земли для определенных культур, или предсказать качество и количество урожая, или
- Обнаружение объектов: подсчитать количество нефтяных танкеров на определенном транспортном маршруте или количество автомобилей на парковке, или определить местоположение покупателей в торговом центре.

### Пример кода: LeNet5 - первая CNN с промышленным применением

Все библиотеки, которые мы представили в предыдущей главе, обеспечивают поддержку сверточных слоев.

Ноутбук [digit_classification_with_lenet5](02_digit_classification_with_lenet5.ipynb) иллюстрирует архитектуру LeNet5 с использованием базового набора данных рукописных цифр MNIST.

### Пример кода: AlexNet - возрождение исследований глубокого обучения

Перенесемся в 2012 год, и мы переходим к более глубокой и современной архитектуре AlexNet. Мы будем использовать набор данных CIFAR10, который использует 60 000 образцов ImageNet, сжатых до разрешения 32x32 пикселя (с исходных 224x224), но все еще с тремя цветовыми каналами. Существует только 10 из исходных 1000 классов.

См. ноутбук [image_classification_with_alexnet](03_image_classification_with_alexnet.ipynb) для реализации, включая использование аугментации данных.

### Пример кода: трансферное обучение с VGG16 на практике

На практике у нас часто нет достаточно данных для обучения CNN с нуля со случайной инициализацией. Трансферное обучение - это метод машинного обучения, который перепрофилирует модель, обученную на одном наборе данных, для другой задачи. Естественно, это работает, если обучение от первой задачи переносится на интересующую задачу. В случае успеха это может привести к лучшей производительности и более быстрому обучению, которое требует меньше размеченных данных, чем обучение нейронной сети с нуля на целевой задаче.

TensorFlow 2, например, содержит предварительно обученные модели для нескольких эталонных архитектур, обсуждавшихся ранее, а именно VGG16 и её более крупную версию VGG19, ResNet50, InceptionV3 и InceptionResNetV2, а также MobileNet, DenseNet, NASNet и MobileNetV2.

Подход трансферного обучения к CNN основывается на предварительном обучении на очень большом наборе данных, таком как ImageNet. Цель состоит в том, чтобы сверточные фильтры извлекли представление признаков, которое обобщается на новые изображения. На втором этапе он использует результат либо для инициализации и повторного обучения новой CNN, либо в качестве входных данных в новую сеть, которая решает интересующую задачу.

Архитектуры CNN обычно используют последовательность сверточных слоев для обнаружения иерархических паттернов, добавляя один или несколько полносвязных слоев для отображения сверточных активаций на классы или значения результата. Выход последнего сверточного слоя, который поступает в полносвязную часть, называется признаками узкого места (bottleneck features). Мы можем использовать признаки узкого места предварительно обученной сети в качестве входных данных в новую полносвязную сеть, обычно после применения функции активации ReLU.

Другими словами, мы замораживаем сверточные слои и заменяем плотную часть сети. Дополнительным преимуществом является то, что мы можем использовать входные данные различных размеров, потому что именно плотные слои ограничивают размер входных данных.

В качестве альтернативы мы можем использовать признаки узкого места в качестве входных данных в другой алгоритм машинного обучения. В архитектуре AlexNet, например, слой узкого места вычисляет вектор с 4096 элементами для каждого входного изображения 224 x 224. Затем мы используем этот вектор в качестве признаков для новой модели.

Кроме того, мы можем пойти дальше и не только заменить и переобучить классификатор поверх CNN с использованием новых данных, но и дообучить веса предварительно обученной CNN. Для этого мы продолжаем обучение, либо только для более поздних слоев, замораживая веса некоторых более ранних слоев. Мотивация состоит в том, чтобы сохранить предположительно более общие паттерны, изученные нижними слоями, такие как детекторы краев или цветных пятен, позволяя при этом более поздним слоям CNN адаптироваться к деталям новой задачи. ImageNet, например, содержит большое разнообразие пород собак, что может привести к представлениям признаков, специально полезным для различения этих классов.

- [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)
- [How transferable are features in deep neural networks?](https://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf), Jason Yosinski и др., NIPS, 2014
- [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)

#### Как извлечь признаки узкого места

Ноутбук [bottleneck_features](09_bottleneck_features.ipynb) иллюстрирует, как загрузить предварительно обученную модель VGG16, либо с финальными слоями для генерации прогнозов, либо без финальных слоев для извлечения выходов, производимых признаками узкого места.

#### Как дообучить предварительно обученную модель

Ноутбук [transfer_learning](10_transfer_learning.ipynb), адаптированный из учебника TensorFlow 2, демонстрирует, как заморозить некоторые или все слои предварительно обученной модели и продолжить обучение с использованием нового полносвязного набора слоев и данных другого формата.

### Пример кода: определение типа землепользования по спутниковым снимкам с использованием трансферного обучения

Спутниковые снимки занимают видное место среди альтернативных данных (см. [Главу 3](../03_alternative_data)). Например, трейдеры сырьевых товаров могут полагаться на спутниковые снимки для прогнозирования предложения определенных культур или активности на горнодобывающих объектах, нефтяного или танкерного трафика.

Чтобы проиллюстрировать работу с этим типом данных, мы загружаем [набор данных EuroSat](https://arxiv.org/abs/1709.00029), включенный в наборы данных TensorFlow 2 (Helber и др. 2017). Набор данных EuroSat включает около 27 000 изображений в формате 64x64, которые представляют 10 различных типов землепользования.

Ноутбук [satellite_images](11_satellite_images.ipynb) загружает архитектуру [DenseNet201](https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet201) из `tensorflow.keras.applications` и заменяет её финальные слои.

Мы используем 10 процентов обучающих изображений для целей валидации и достигаем лучшей точности классификации вне выборки 97,96 процента после десяти эпох. Это превышает производительность, указанную в оригинальной статье для наиболее производительной архитектуры ResNet-50 с разделением 90-10.

### Пример кода: обнаружение объектов на практике с номерами домов Google Street View

Обнаружение объектов требует способности различать несколько классов объектов и решать, сколько и какие из этих объектов присутствуют на изображении.

Ярким примером является идентификация номеров домов Ian Goodfellow из набора данных Google Street View. Она требует идентифицировать:
- сколько из максимум пяти цифр составляют номер дома,
- правильную цифру для каждого компонента, и
- правильный порядок составляющих цифр.

См. директорию [data](../data) для инструкций по получению набора данных.

#### Предварительная обработка исходных изображений

Ноутбук [svhn_preprocessing](12_svhn_preprocessing.ipynb) содержит код для создания упрощенного, обрезанного набора данных, который использует информацию об ограничивающих рамках для создания изображений правильной формы 32x32, содержащих цифры; исходные изображения имеют произвольную форму.

#### Трансферное обучение с пользовательским финальным слоем для множественных выходов

Ноутбук [svhn_object_detection](13_svhn_object_detection.ipynb) продолжает иллюстрировать, как построить глубокую CNN с использованием функционального API Keras для генерации множественных выходов: одного для прогнозирования количества присутствующих цифр и пяти для значения каждой в порядке их появления.

## CNN для данных временных рядов: прогнозирование доходности акций

CNN изначально были разработаны для обработки данных изображений и достигли сверхчеловеческой производительности в различных задачах компьютерного зрения. Как обсуждалось в первом разделе, данные временных рядов имеют сеточную структуру, похожую на структуру изображений, и CNN успешно применялись к одно-, двух- и трехмерным представлениям временных данных.

Применение CNN к временным рядам, скорее всего, принесет плоды, если данные соответствуют ключевому предположению модели о том, что локальные паттерны или отношения помогают предсказать результат. В контексте временных рядов локальные паттерны могут быть автокорреляцией или подобными нелинейными отношениями на релевантных интервалах. Вдоль второго и третьего измерения локальные паттерны подразумевают систематические отношения между различными компонентами многомерного ряда или между этими рядами для разных тикеров. Поскольку локальность имеет значение, важно, чтобы данные были организованы соответствующим образом, в отличие от сетей прямого распространения, где перетасовка элементов любого измерения не влияет негативно на процесс обучения.

### Пример кода: построение авторегрессионной CNN с 1D-свертками

Мы представим случай использования временных рядов для CNN с одномерной авторегрессионной моделью доходности активов. Более конкретно, модель получает последние 12 месяцев доходности и использует один слой одномерных сверток для прогнозирования следующего месяца.

Ноутбук [time_series_prediction](04_time_series_prediction.ipynb) иллюстрирует случай использования временных рядов с примером прогноза одномерной цены актива, который мы представили в предыдущей главе. Напомним, что мы создаем скользящие месячные доходности акций и используем 24 лагированных доходности наряду с one-hot кодированной информацией о месяце для прогнозирования того, будет ли следующая месячная доходность положительной или отрицательной.

### Пример кода: CNN-TA - кластеризация финансовых временных рядов в 2D-формате изображений

Чтобы использовать сеточную структуру данных временных рядов, мы можем использовать архитектуры CNN для одномерных и многомерных временных рядов. В последнем случае мы рассматриваем различные временные ряды как каналы, подобно различным цветовым сигналам.

Альтернативный подход преобразует временной ряд альфа-факторов в двумерный формат для использования способности CNN обнаруживать локальные паттерны. [Sezer и Ozbayoglu](https://www.sciencedirect.com/science/article/abs/pii/S1568494618302151) (2018) предлагают [CNN-TA](https://github.com/omerbsezer/CNN-TA), который вычисляет 15 технических индикаторов для различных интервалов и использует иерархическую кластеризацию (см. Главу 13) для размещения индикаторов, которые ведут себя похоже, близко друг к другу в 2D-сетке.

#### Создание 2D временных рядов финансовых индикаторов

Ноутбук [engineer_cnn_features](05_cnn_for_trading_feature_engineering.ipynb) создает технические индикаторы на различных интервалах.

#### Выбор и кластеризация наиболее релевантных признаков

Ноутбук [convert_cnn_features_to_image_format](06_cnn_for_trading_features_to_clustered_image_format.ipynb) выбирает 15 наиболее релевантных признаков из 20 кандидатов для заполнения входной сетки 15⨉15 и затем применяет иерархическую кластеризацию.

#### Создание и обучение сверточной нейронной сети

Теперь мы готовы спроектировать, обучить и оценить CNN, следуя шагам, описанным в предыдущем разделе. Ноутбук [cnn_for_trading](07_cnn_for_trading.ipynb) содержит соответствующие примеры кода.

#### Бэктестинг long-short торговой стратегии

Чтобы получить представление о качестве сигнала, мы вычисляем спред между равновзвешенными портфелями, инвестированными в акции, выбранные в соответствии с квинтилями сигнала, используя [Alphalens](https://github.com/quantopian/alphalens) (см. [Главу 4](../04_alpha_factor_research)).

<p align="center">
<img src="https://i.imgur.com/JlKttDL.png" width="80%">
</p>
