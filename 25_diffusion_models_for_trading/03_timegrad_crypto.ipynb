{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeGrad: Автореgrессивная диффузия для криптовалют\n",
    "\n",
    "TimeGrad - это авторегрессивная модель диффузии, разработанная Amazon (2021), которая комбинирует RNN для кодирования контекста с диффузионной моделью для генерации вероятностных прогнозов.\n",
    "\n",
    "## Основные компоненты TimeGrad:\n",
    "\n",
    "1. **RNN Encoder**: Кодирует исторический контекст в скрытое состояние\n",
    "2. **Diffusion Decoder**: Генерирует прогнозы через обратный диффузионный процесс\n",
    "3. **Autoregressive Generation**: Прогнозы генерируются пошагово\n",
    "\n",
    "## Преимущества TimeGrad:\n",
    "\n",
    "- Вероятностные прогнозы с квантилями\n",
    "- Хорошо работает с мультивариантными временными рядами\n",
    "- Естественная оценка неопределённости\n",
    "\n",
    "![TimeGrad Architecture](https://raw.githubusercontent.com/zalandoresearch/pytorch-ts/master/docs/source/_static/timegrad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка зависимостей\n",
    "!pip install torch numpy pandas matplotlib seaborn scikit-learn tqdm requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, Optional, List, Dict\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка стиля\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Устройство\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Получение данных криптовалют"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class CryptoDataFetcher:\n",
    "    \"\"\"Получение данных криптовалют через Bybit API.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.bybit.com/v5/market/kline\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def fetch_ohlcv(\n",
    "        self, \n",
    "        symbol: str = \"BTCUSDT\",\n",
    "        interval: str = \"60\",  # 1 час\n",
    "        days: int = 90\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Получить OHLCV данные.\"\"\"\n",
    "        \n",
    "        all_data = []\n",
    "        end_time = int(datetime.now().timestamp() * 1000)\n",
    "        start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)\n",
    "        \n",
    "        current_end = end_time\n",
    "        \n",
    "        while current_end > start_time:\n",
    "            params = {\n",
    "                \"category\": \"spot\",\n",
    "                \"symbol\": symbol,\n",
    "                \"interval\": interval,\n",
    "                \"end\": current_end,\n",
    "                \"limit\": 200\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = self.session.get(self.BASE_URL, params=params)\n",
    "                data = response.json()\n",
    "                \n",
    "                if data.get(\"retCode\") != 0:\n",
    "                    print(f\"API Error: {data.get('retMsg')}\")\n",
    "                    break\n",
    "                \n",
    "                klines = data.get(\"result\", {}).get(\"list\", [])\n",
    "                if not klines:\n",
    "                    break\n",
    "                \n",
    "                all_data.extend(klines)\n",
    "                current_end = int(klines[-1][0]) - 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                break\n",
    "        \n",
    "        if not all_data:\n",
    "            # Создаём синтетические данные если API недоступен\n",
    "            return self._generate_synthetic_data(days * 24)\n",
    "        \n",
    "        # Преобразуем в DataFrame\n",
    "        df = pd.DataFrame(all_data, columns=[\n",
    "            'timestamp', 'open', 'high', 'low', 'close', 'volume', 'turnover'\n",
    "        ])\n",
    "        \n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'].astype(int), unit='ms')\n",
    "        for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "            df[col] = df[col].astype(float)\n",
    "        \n",
    "        df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "        return df\n",
    "    \n",
    "    def _generate_synthetic_data(self, n_points: int) -> pd.DataFrame:\n",
    "        \"\"\"Генерация синтетических данных для тестирования.\"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Геометрическое броуновское движение\n",
    "        dt = 1/24  # 1 час\n",
    "        mu = 0.0001  # drift\n",
    "        sigma = 0.02  # volatility\n",
    "        \n",
    "        S0 = 50000  # начальная цена BTC\n",
    "        returns = np.random.normal(mu * dt, sigma * np.sqrt(dt), n_points)\n",
    "        prices = S0 * np.exp(np.cumsum(returns))\n",
    "        \n",
    "        # OHLCV\n",
    "        high = prices * (1 + np.abs(np.random.normal(0, 0.005, n_points)))\n",
    "        low = prices * (1 - np.abs(np.random.normal(0, 0.005, n_points)))\n",
    "        open_prices = np.roll(prices, 1)\n",
    "        open_prices[0] = S0\n",
    "        volume = np.random.exponential(1000, n_points)\n",
    "        \n",
    "        timestamps = pd.date_range(\n",
    "            end=datetime.now(),\n",
    "            periods=n_points,\n",
    "            freq='H'\n",
    "        )\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'open': open_prices,\n",
    "            'high': high,\n",
    "            'low': low,\n",
    "            'close': prices,\n",
    "            'volume': volume\n",
    "        })\n",
    "\n",
    "# Получаем данные\n",
    "fetcher = CryptoDataFetcher()\n",
    "df = fetcher.fetch_ohlcv(symbol=\"BTCUSDT\", interval=\"60\", days=90)\n",
    "print(f\"Получено {len(df)} записей\")\n",
    "print(f\"Период: {df['timestamp'].min()} - {df['timestamp'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация данных\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Цена\n",
    "axes[0].plot(df['timestamp'], df['close'], linewidth=0.8)\n",
    "axes[0].set_title('BTC/USDT Price (Hourly)', fontsize=14)\n",
    "axes[0].set_ylabel('Price (USD)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Объём\n",
    "axes[1].bar(df['timestamp'], df['volume'], width=0.03, alpha=0.7)\n",
    "axes[1].set_title('Trading Volume', fontsize=14)\n",
    "axes[1].set_ylabel('Volume')\n",
    "axes[1].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    \"\"\"Вычисление технических индикаторов.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_returns(df: pd.DataFrame, periods: List[int] = [1, 6, 24]) -> pd.DataFrame:\n",
    "        \"\"\"Вычислить логарифмические доходности.\"\"\"\n",
    "        for p in periods:\n",
    "            df[f'return_{p}h'] = np.log(df['close'] / df['close'].shift(p))\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_volatility(df: pd.DataFrame, windows: List[int] = [12, 24, 72]) -> pd.DataFrame:\n",
    "        \"\"\"Вычислить реализованную волатильность.\"\"\"\n",
    "        for w in windows:\n",
    "            df[f'volatility_{w}h'] = df['return_1h'].rolling(w).std() * np.sqrt(24)\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rsi(df: pd.DataFrame, period: int = 14) -> pd.DataFrame:\n",
    "        \"\"\"Вычислить RSI.\"\"\"\n",
    "        delta = df['close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "        rs = gain / loss\n",
    "        df['rsi'] = 100 - (100 / (1 + rs))\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_macd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Вычислить MACD.\"\"\"\n",
    "        ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "        ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "        df['macd'] = ema12 - ema26\n",
    "        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "        df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_bollinger(df: pd.DataFrame, period: int = 20) -> pd.DataFrame:\n",
    "        \"\"\"Вычислить Bollinger Bands.\"\"\"\n",
    "        sma = df['close'].rolling(period).mean()\n",
    "        std = df['close'].rolling(period).std()\n",
    "        df['bb_upper'] = sma + 2 * std\n",
    "        df['bb_lower'] = sma - 2 * std\n",
    "        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / sma\n",
    "        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_atr(df: pd.DataFrame, period: int = 14) -> pd.DataFrame:\n",
    "        \"\"\"Вычислить Average True Range.\"\"\"\n",
    "        high_low = df['high'] - df['low']\n",
    "        high_close = np.abs(df['high'] - df['close'].shift())\n",
    "        low_close = np.abs(df['low'] - df['close'].shift())\n",
    "        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "        df['atr'] = tr.rolling(period).mean()\n",
    "        df['atr_pct'] = df['atr'] / df['close'] * 100\n",
    "        return df\n",
    "    \n",
    "    def compute_all(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Вычислить все признаки.\"\"\"\n",
    "        df = df.copy()\n",
    "        df = self.compute_returns(df)\n",
    "        df = self.compute_volatility(df)\n",
    "        df = self.compute_rsi(df)\n",
    "        df = self.compute_macd(df)\n",
    "        df = self.compute_bollinger(df)\n",
    "        df = self.compute_atr(df)\n",
    "        return df.dropna()\n",
    "\n",
    "# Вычисляем признаки\n",
    "engineer = FeatureEngineer()\n",
    "df_features = engineer.compute_all(df)\n",
    "print(f\"Признаки: {list(df_features.columns)}\")\n",
    "print(f\"Записей после feature engineering: {len(df_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Подготовка данных для TimeGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем признаки для модели\n",
    "feature_columns = [\n",
    "    'close', 'volume', \n",
    "    'return_1h', 'return_6h', 'return_24h',\n",
    "    'volatility_12h', 'volatility_24h',\n",
    "    'rsi', 'macd_hist', 'bb_position', 'atr_pct'\n",
    "]\n",
    "\n",
    "# Нормализация\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_features[feature_columns]),\n",
    "    columns=feature_columns,\n",
    "    index=df_features.index\n",
    ")\n",
    "\n",
    "print(f\"Нормализованные данные: {df_scaled.shape}\")\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TimeGradConfig:\n",
    "    \"\"\"Конфигурация TimeGrad.\"\"\"\n",
    "    context_length: int = 72      # 3 дня истории\n",
    "    prediction_length: int = 24   # 24 часа прогноза\n",
    "    input_dim: int = 11           # количество признаков\n",
    "    hidden_dim: int = 128         # размерность RNN\n",
    "    num_layers: int = 2           # количество слоёв RNN\n",
    "    diffusion_steps: int = 100    # шаги диффузии\n",
    "    beta_start: float = 1e-4\n",
    "    beta_end: float = 0.02\n",
    "    \n",
    "config = TimeGradConfig(input_dim=len(feature_columns))\n",
    "print(f\"Config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Создать последовательности для обучения.\"\"\"\n",
    "    \n",
    "    total_length = context_length + prediction_length\n",
    "    n_samples = len(data) - total_length + 1\n",
    "    \n",
    "    X = []  # context\n",
    "    y = []  # target\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        X.append(data[i:i+context_length])\n",
    "        y.append(data[i+context_length:i+total_length, 0])  # только close\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Создаём последовательности\n",
    "data_np = df_scaled.values\n",
    "X, y = create_sequences(data_np, config.context_length, config.prediction_length)\n",
    "\n",
    "# Train/val/test split\n",
    "n = len(X)\n",
    "train_size = int(0.7 * n)\n",
    "val_size = int(0.15 * n)\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TimeGrad Architecture\n",
    "\n",
    "TimeGrad состоит из:\n",
    "1. **RNN Encoder** - кодирует исторический контекст\n",
    "2. **Diffusion Network** - денойзер для диффузии\n",
    "3. **Autoregressive Decoder** - генерирует прогнозы пошагово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    \"\"\"Синусоидальное позиционное кодирование для времени диффузии.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = np.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat([embeddings.sin(), embeddings.cos()], dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    \"\"\"RNN энкодер для исторического контекста.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, seq_len, input_dim]\n",
    "        Returns:\n",
    "            outputs: [batch, seq_len, hidden_dim]\n",
    "            hidden: final hidden state\n",
    "        \"\"\"\n",
    "        outputs, (h_n, c_n) = self.rnn(x)\n",
    "        # Берём последний скрытый слой\n",
    "        hidden = h_n[-1]  # [batch, hidden_dim]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionDenoiser(nn.Module):\n",
    "    \"\"\"Денойзер для TimeGrad.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        context_dim: int,\n",
    "        time_dim: int = 64\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Кодирование времени диффузии\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalPositionEmbedding(time_dim),\n",
    "            nn.Linear(time_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Объединение входа, контекста и времени\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        self.context_proj = nn.Linear(context_dim, hidden_dim)\n",
    "        \n",
    "        # MLP для денойзинга\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,      # [batch, input_dim] - зашумлённый вход\n",
    "        t: torch.Tensor,      # [batch] - шаг диффузии\n",
    "        context: torch.Tensor # [batch, context_dim] - контекст от RNN\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Предсказание шума.\n",
    "        \"\"\"\n",
    "        # Кодируем компоненты\n",
    "        x_emb = self.input_proj(x)\n",
    "        t_emb = self.time_embed(t)\n",
    "        ctx_emb = self.context_proj(context)\n",
    "        \n",
    "        # Объединяем\n",
    "        combined = torch.cat([x_emb, t_emb, ctx_emb], dim=-1)\n",
    "        \n",
    "        # Предсказываем шум\n",
    "        noise_pred = self.net(combined)\n",
    "        \n",
    "        return noise_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeGrad(nn.Module):\n",
    "    \"\"\"TimeGrad: Autoregressive Denoising Diffusion Model for Time Series.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TimeGradConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        # RNN Encoder\n",
    "        self.encoder = RNNEncoder(\n",
    "            input_dim=config.input_dim,\n",
    "            hidden_dim=config.hidden_dim,\n",
    "            num_layers=config.num_layers\n",
    "        )\n",
    "        \n",
    "        # Diffusion Denoiser (для одномерного выхода - close price)\n",
    "        self.denoiser = DiffusionDenoiser(\n",
    "            input_dim=1,  # предсказываем только close\n",
    "            hidden_dim=config.hidden_dim,\n",
    "            context_dim=config.hidden_dim\n",
    "        )\n",
    "        \n",
    "        # Noise schedule\n",
    "        self.register_buffer(\n",
    "            'betas', \n",
    "            torch.linspace(config.beta_start, config.beta_end, config.diffusion_steps)\n",
    "        )\n",
    "        alphas = 1 - self.betas\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', torch.cumprod(alphas, dim=0))\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(self.alphas_cumprod))\n",
    "        self.register_buffer(\n",
    "            'sqrt_one_minus_alphas_cumprod', \n",
    "            torch.sqrt(1 - self.alphas_cumprod)\n",
    "        )\n",
    "    \n",
    "    def forward_diffusion(\n",
    "        self, \n",
    "        x0: torch.Tensor, \n",
    "        t: torch.Tensor,\n",
    "        noise: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Прямой диффузионный процесс.\n",
    "        \n",
    "        Args:\n",
    "            x0: [batch, dim] - чистые данные\n",
    "            t: [batch] - шаги времени\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        \n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t].unsqueeze(-1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].unsqueeze(-1)\n",
    "        \n",
    "        xt = sqrt_alpha * x0 + sqrt_one_minus_alpha * noise\n",
    "        \n",
    "        return xt, noise\n",
    "    \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        context: torch.Tensor,  # [batch, context_len, input_dim]\n",
    "        target: torch.Tensor    # [batch, pred_len]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Вычислить loss для обучения.\n",
    "        \"\"\"\n",
    "        batch_size = context.shape[0]\n",
    "        device = context.device\n",
    "        \n",
    "        # Кодируем контекст\n",
    "        _, hidden = self.encoder(context)\n",
    "        \n",
    "        # Выбираем случайный шаг прогноза для обучения\n",
    "        pred_step = torch.randint(0, self.config.prediction_length, (batch_size,))\n",
    "        x0 = target[torch.arange(batch_size), pred_step].unsqueeze(-1)  # [batch, 1]\n",
    "        \n",
    "        # Случайный шаг диффузии\n",
    "        t = torch.randint(0, self.config.diffusion_steps, (batch_size,), device=device)\n",
    "        \n",
    "        # Прямая диффузия\n",
    "        xt, noise = self.forward_diffusion(x0, t)\n",
    "        \n",
    "        # Предсказание шума\n",
    "        noise_pred = self.denoiser(xt, t.float(), hidden)\n",
    "        \n",
    "        # MSE loss\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        context: torch.Tensor,\n",
    "        num_samples: int = 100\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Генерировать прогнозы через DDPM sampling.\n",
    "        \n",
    "        Args:\n",
    "            context: [batch, context_len, input_dim]\n",
    "            num_samples: количество Monte Carlo samples\n",
    "            \n",
    "        Returns:\n",
    "            forecasts: [batch, num_samples, pred_len]\n",
    "        \"\"\"\n",
    "        batch_size = context.shape[0]\n",
    "        device = context.device\n",
    "        \n",
    "        # Кодируем контекст\n",
    "        _, hidden = self.encoder(context)\n",
    "        \n",
    "        all_forecasts = []\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            # Авторегрессивная генерация\n",
    "            forecasts = []\n",
    "            \n",
    "            for step in range(self.config.prediction_length):\n",
    "                # Начинаем с шума\n",
    "                xt = torch.randn(batch_size, 1, device=device)\n",
    "                \n",
    "                # Обратный процесс диффузии\n",
    "                for t in reversed(range(self.config.diffusion_steps)):\n",
    "                    t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.float)\n",
    "                    \n",
    "                    # Предсказываем шум\n",
    "                    noise_pred = self.denoiser(xt, t_tensor, hidden)\n",
    "                    \n",
    "                    # DDPM update\n",
    "                    alpha = self.alphas[t]\n",
    "                    alpha_cumprod = self.alphas_cumprod[t]\n",
    "                    beta = self.betas[t]\n",
    "                    \n",
    "                    if t > 0:\n",
    "                        noise = torch.randn_like(xt)\n",
    "                        sigma = torch.sqrt(beta)\n",
    "                    else:\n",
    "                        noise = 0\n",
    "                        sigma = 0\n",
    "                    \n",
    "                    xt = (1 / torch.sqrt(alpha)) * (\n",
    "                        xt - (beta / torch.sqrt(1 - alpha_cumprod)) * noise_pred\n",
    "                    ) + sigma * noise\n",
    "                \n",
    "                forecasts.append(xt)\n",
    "            \n",
    "            # [batch, pred_len]\n",
    "            sample_forecast = torch.cat(forecasts, dim=-1)\n",
    "            all_forecasts.append(sample_forecast)\n",
    "        \n",
    "        # [batch, num_samples, pred_len]\n",
    "        return torch.stack(all_forecasts, dim=1)\n",
    "\n",
    "# Создаём модель\n",
    "model = TimeGrad(config).to(device)\n",
    "print(f\"Параметров: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Обучение TimeGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: TimeGrad,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    \"\"\"Обучить одну эпоху.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for context, target in loader:\n",
    "        context = context.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model.compute_loss(context, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(\n",
    "    model: TimeGrad,\n",
    "    loader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    \"\"\"Валидация модели.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for context, target in loader:\n",
    "            context = context.to(device)\n",
    "            target = target.to(device)\n",
    "            loss = model.compute_loss(context, target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "n_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc=\"Training\"):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n",
    "\n",
    "# Загружаем лучшую модель\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"\\nЛучший Val Loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График обучения\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.plot(train_losses, label='Train Loss', alpha=0.8)\n",
    "ax.plot(val_losses, label='Val Loss', alpha=0.8)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('TimeGrad Training Progress')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Генерация прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forecasts(\n",
    "    model: TimeGrad,\n",
    "    context: torch.Tensor,\n",
    "    num_samples: int = 100\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Генерировать вероятностные прогнозы.\n",
    "    \n",
    "    Returns:\n",
    "        dict с mean, std, quantiles\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # [batch, num_samples, pred_len]\n",
    "        samples = model.sample(context, num_samples)\n",
    "    \n",
    "    samples_np = samples.cpu().numpy()\n",
    "    \n",
    "    return {\n",
    "        'samples': samples_np,\n",
    "        'mean': samples_np.mean(axis=1),\n",
    "        'std': samples_np.std(axis=1),\n",
    "        'q10': np.percentile(samples_np, 10, axis=1),\n",
    "        'q50': np.percentile(samples_np, 50, axis=1),\n",
    "        'q90': np.percentile(samples_np, 90, axis=1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем прогнозы на тестовых данных\n",
    "test_context, test_target = next(iter(test_loader))\n",
    "test_context = test_context.to(device)\n",
    "\n",
    "print(\"Генерация прогнозов (это может занять время)...\")\n",
    "forecasts = generate_forecasts(model, test_context[:5], num_samples=50)\n",
    "\n",
    "print(f\"Форма прогнозов: {forecasts['mean'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация прогнозов\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(4):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Истинные значения (нормализованные)\n",
    "    true_values = test_target[i].numpy()\n",
    "    \n",
    "    # Прогнозы\n",
    "    mean = forecasts['mean'][i]\n",
    "    q10 = forecasts['q10'][i]\n",
    "    q90 = forecasts['q90'][i]\n",
    "    \n",
    "    hours = np.arange(1, config.prediction_length + 1)\n",
    "    \n",
    "    # Доверительный интервал\n",
    "    ax.fill_between(hours, q10, q90, alpha=0.3, label='80% CI')\n",
    "    ax.plot(hours, mean, 'b-', linewidth=2, label='Forecast Mean')\n",
    "    ax.plot(hours, true_values, 'r--', linewidth=2, label='Actual')\n",
    "    \n",
    "    ax.set_xlabel('Hours Ahead')\n",
    "    ax.set_ylabel('Normalized Price')\n",
    "    ax.set_title(f'Sample {i+1}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('TimeGrad Probabilistic Forecasts', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Оценка качества прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    predictions: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    quantile_forecasts: Optional[Dict] = None\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Вычислить метрики качества прогнозов.\"\"\"\n",
    "    \n",
    "    # Point forecast metrics\n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(predictions - targets))\n",
    "    \n",
    "    # MAPE (avoiding division by zero)\n",
    "    mask = targets != 0\n",
    "    mape = np.mean(np.abs((predictions[mask] - targets[mask]) / targets[mask])) * 100\n",
    "    \n",
    "    metrics = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    # Calibration metrics for probabilistic forecasts\n",
    "    if quantile_forecasts is not None:\n",
    "        q10 = quantile_forecasts['q10']\n",
    "        q90 = quantile_forecasts['q90']\n",
    "        \n",
    "        # Coverage: какая доля истинных значений попала в интервал\n",
    "        in_interval = (targets >= q10) & (targets <= q90)\n",
    "        coverage = np.mean(in_interval)\n",
    "        \n",
    "        # Interval width\n",
    "        interval_width = np.mean(q90 - q10)\n",
    "        \n",
    "        metrics['Coverage_80'] = coverage\n",
    "        metrics['Interval_Width'] = interval_width\n",
    "        \n",
    "        # CRPS (Continuous Ranked Probability Score) - simplified\n",
    "        samples = quantile_forecasts.get('samples')\n",
    "        if samples is not None:\n",
    "            # Approximate CRPS\n",
    "            crps = np.mean(np.abs(samples - targets[:, np.newaxis, :]).mean(axis=1))\n",
    "            metrics['CRPS'] = crps\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка на тестовых данных\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "all_forecasts = {'q10': [], 'q90': [], 'samples': []}\n",
    "\n",
    "print(\"Оценка на тестовых данных...\")\n",
    "for context, target in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "    context = context.to(device)\n",
    "    \n",
    "    forecasts = generate_forecasts(model, context, num_samples=30)\n",
    "    \n",
    "    all_predictions.append(forecasts['mean'])\n",
    "    all_targets.append(target.numpy())\n",
    "    all_forecasts['q10'].append(forecasts['q10'])\n",
    "    all_forecasts['q90'].append(forecasts['q90'])\n",
    "    all_forecasts['samples'].append(forecasts['samples'])\n",
    "\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "quantile_forecasts = {\n",
    "    'q10': np.concatenate(all_forecasts['q10'], axis=0),\n",
    "    'q90': np.concatenate(all_forecasts['q90'], axis=0),\n",
    "    'samples': np.concatenate(all_forecasts['samples'], axis=0)\n",
    "}\n",
    "\n",
    "metrics = compute_metrics(predictions, targets, quantile_forecasts)\n",
    "\n",
    "print(\"\\n=== Метрики TimeGrad ===\")\n",
    "for name, value in metrics.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Калибровочный график\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 1. Предсказания vs Факт\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(targets.flatten(), predictions.flatten(), alpha=0.1, s=1)\n",
    "min_val, max_val = targets.min(), targets.max()\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect')\n",
    "ax1.set_xlabel('Actual')\n",
    "ax1.set_ylabel('Predicted')\n",
    "ax1.set_title('Predictions vs Actual')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Распределение ошибок по горизонту\n",
    "ax2 = axes[1]\n",
    "errors_by_horizon = np.abs(predictions - targets)\n",
    "mae_by_horizon = errors_by_horizon.mean(axis=0)\n",
    "std_by_horizon = errors_by_horizon.std(axis=0)\n",
    "\n",
    "hours = np.arange(1, config.prediction_length + 1)\n",
    "ax2.fill_between(hours, mae_by_horizon - std_by_horizon, \n",
    "                  mae_by_horizon + std_by_horizon, alpha=0.3)\n",
    "ax2.plot(hours, mae_by_horizon, 'b-', linewidth=2)\n",
    "ax2.set_xlabel('Forecast Horizon (hours)')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.set_title('Error by Forecast Horizon')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Сравнение с базовыми моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveForecaster:\n",
    "    \"\"\"Наивный прогноз: повторяем последнее значение.\"\"\"\n",
    "    \n",
    "    def predict(self, context: np.ndarray, horizon: int) -> np.ndarray:\n",
    "        last_value = context[:, -1, 0]  # последний close\n",
    "        return np.tile(last_value[:, np.newaxis], (1, horizon))\n",
    "\n",
    "\n",
    "class SeasonalNaiveForecaster:\n",
    "    \"\"\"Сезонный наивный: повторяем значения из прошлой недели.\"\"\"\n",
    "    \n",
    "    def predict(self, context: np.ndarray, horizon: int) -> np.ndarray:\n",
    "        # Берём значения из того же времени неделю назад (если есть)\n",
    "        seasonal_period = 24 * 7  # неделя в часах\n",
    "        if context.shape[1] >= seasonal_period:\n",
    "            return context[:, -seasonal_period:-seasonal_period+horizon, 0]\n",
    "        else:\n",
    "            # Fallback на наивный\n",
    "            return NaiveForecaster().predict(context, horizon)\n",
    "\n",
    "\n",
    "# Оценка базовых моделей\n",
    "naive = NaiveForecaster()\n",
    "\n",
    "naive_predictions = []\n",
    "for context, target in test_loader:\n",
    "    pred = naive.predict(context.numpy(), config.prediction_length)\n",
    "    naive_predictions.append(pred)\n",
    "\n",
    "naive_predictions = np.concatenate(naive_predictions, axis=0)\n",
    "naive_metrics = compute_metrics(naive_predictions, targets)\n",
    "\n",
    "print(\"=== Сравнение моделей ===\")\n",
    "print(f\"\\nTimeGrad:\")\n",
    "print(f\"  RMSE: {metrics['RMSE']:.4f}\")\n",
    "print(f\"  MAE:  {metrics['MAE']:.4f}\")\n",
    "print(f\"  Coverage (80%): {metrics.get('Coverage_80', 'N/A'):.2%}\")\n",
    "\n",
    "print(f\"\\nNaive (Last Value):\")\n",
    "print(f\"  RMSE: {naive_metrics['RMSE']:.4f}\")\n",
    "print(f\"  MAE:  {naive_metrics['MAE']:.4f}\")\n",
    "\n",
    "print(f\"\\nОтносительное улучшение RMSE: {(1 - metrics['RMSE']/naive_metrics['RMSE'])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Генерация реального прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_forecast(\n",
    "    model: TimeGrad,\n",
    "    df: pd.DataFrame,\n",
    "    feature_columns: List[str],\n",
    "    scaler: StandardScaler,\n",
    "    config: TimeGradConfig,\n",
    "    num_samples: int = 100\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Генерировать прогноз на реальных данных.\n",
    "    \"\"\"\n",
    "    # Подготовка контекста\n",
    "    context_data = df[feature_columns].iloc[-config.context_length:].values\n",
    "    context_scaled = scaler.transform(context_data)\n",
    "    context_tensor = torch.FloatTensor(context_scaled).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Генерация прогнозов\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        samples = model.sample(context_tensor, num_samples)\n",
    "    \n",
    "    samples_np = samples.cpu().numpy()[0]  # [num_samples, pred_len]\n",
    "    \n",
    "    # Денормализация (только для close price - индекс 0)\n",
    "    close_mean = scaler.mean_[0]\n",
    "    close_std = scaler.scale_[0]\n",
    "    \n",
    "    samples_denorm = samples_np * close_std + close_mean\n",
    "    \n",
    "    # Формируем DataFrame с прогнозами\n",
    "    last_timestamp = df['timestamp'].iloc[-1]\n",
    "    forecast_times = pd.date_range(\n",
    "        start=last_timestamp + pd.Timedelta(hours=1),\n",
    "        periods=config.prediction_length,\n",
    "        freq='H'\n",
    "    )\n",
    "    \n",
    "    forecast_df = pd.DataFrame({\n",
    "        'timestamp': forecast_times,\n",
    "        'mean': samples_denorm.mean(axis=0),\n",
    "        'std': samples_denorm.std(axis=0),\n",
    "        'q10': np.percentile(samples_denorm, 10, axis=0),\n",
    "        'q50': np.percentile(samples_denorm, 50, axis=0),\n",
    "        'q90': np.percentile(samples_denorm, 90, axis=0),\n",
    "    })\n",
    "    \n",
    "    return forecast_df\n",
    "\n",
    "# Генерируем прогноз\n",
    "forecast_df = generate_real_forecast(\n",
    "    model, df_features, feature_columns, scaler, config, num_samples=100\n",
    ")\n",
    "\n",
    "print(\"=== Прогноз на следующие 24 часа ===\")\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация прогноза\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Историческая цена (последние 7 дней)\n",
    "history = df.tail(24 * 7)\n",
    "ax.plot(history['timestamp'], history['close'], 'b-', linewidth=1, label='Historical')\n",
    "\n",
    "# Прогноз\n",
    "ax.fill_between(\n",
    "    forecast_df['timestamp'],\n",
    "    forecast_df['q10'],\n",
    "    forecast_df['q90'],\n",
    "    alpha=0.3,\n",
    "    color='orange',\n",
    "    label='80% CI'\n",
    ")\n",
    "ax.plot(\n",
    "    forecast_df['timestamp'],\n",
    "    forecast_df['mean'],\n",
    "    'orange',\n",
    "    linewidth=2,\n",
    "    label='Forecast'\n",
    ")\n",
    "\n",
    "# Вертикальная линия - граница прогноза\n",
    "ax.axvline(df['timestamp'].iloc[-1], color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Price (USD)')\n",
    "ax.set_title('TimeGrad BTC/USDT 24-Hour Forecast')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Выводы\n",
    "\n",
    "### Преимущества TimeGrad:\n",
    "\n",
    "1. **Вероятностные прогнозы**: Модель генерирует распределение возможных исходов, а не точечную оценку\n",
    "2. **Естественная оценка неопределённости**: Квантили позволяют строить доверительные интервалы\n",
    "3. **Гибкость**: RNN-энкодер хорошо захватывает временные зависимости\n",
    "\n",
    "### Ограничения:\n",
    "\n",
    "1. **Вычислительная сложность**: Генерация сэмплов требует много итераций диффузии\n",
    "2. **Авторегрессивность**: Ошибки накапливаются для длинных горизонтов\n",
    "3. **Калибровка**: Может потребоваться дополнительная настройка для корректного покрытия\n",
    "\n",
    "### Рекомендации:\n",
    "\n",
    "- Используйте DDIM сэмплирование для ускорения генерации\n",
    "- Рассмотрите ансамбль моделей для улучшения калибровки\n",
    "- Для длинных горизонтов рассмотрите non-autoregressive методы (CSDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': config,\n",
    "    'scaler_mean': scaler.mean_,\n",
    "    'scaler_scale': scaler.scale_,\n",
    "    'feature_columns': feature_columns,\n",
    "    'metrics': metrics\n",
    "}, 'timegrad_btcusdt.pt')\n",
    "\n",
    "print(\"Модель сохранена в timegrad_btcusdt.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
