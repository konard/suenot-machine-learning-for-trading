{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPM Implementation from Scratch\n",
    "\n",
    "This notebook implements a complete Denoising Diffusion Probabilistic Model (DDPM) from scratch using PyTorch:\n",
    "\n",
    "1. U-Net architecture for noise prediction\n",
    "2. Training loop with proper loss computation\n",
    "3. DDPM and DDIM sampling algorithms\n",
    "4. Visualization of the denoising process\n",
    "\n",
    "Based on: [Ho et al., 2020 - Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noise Schedule\n",
    "\n",
    "The noise schedule defines how much noise is added at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"Gaussian diffusion process with configurable noise schedule.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_timesteps=1000, beta_schedule='cosine', beta_start=1e-4, beta_end=0.02):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "        # Create beta schedule\n",
    "        if beta_schedule == 'linear':\n",
    "            betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        elif beta_schedule == 'cosine':\n",
    "            betas = self._cosine_beta_schedule(num_timesteps)\n",
    "        elif beta_schedule == 'quadratic':\n",
    "            betas = torch.linspace(beta_start**0.5, beta_end**0.5, num_timesteps) ** 2\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown schedule: {beta_schedule}\")\n",
    "        \n",
    "        self.betas = betas\n",
    "        self.alphas = 1.0 - betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "        \n",
    "        # Calculations for diffusion q(x_t | x_0)\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        \n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        self.posterior_log_variance_clipped = torch.log(torch.clamp(self.posterior_variance, min=1e-20))\n",
    "        self.posterior_mean_coef1 = betas * torch.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        self.posterior_mean_coef2 = (1.0 - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (1.0 - self.alphas_cumprod)\n",
    "    \n",
    "    def _cosine_beta_schedule(self, timesteps, s=0.008):\n",
    "        \"\"\"Cosine schedule from 'Improved DDPM'.\"\"\"\n",
    "        steps = timesteps + 1\n",
    "        x = torch.linspace(0, timesteps, steps)\n",
    "        alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        return torch.clip(betas, 0.0001, 0.9999)\n",
    "    \n",
    "    def q_sample(self, x_0, t, noise=None):\n",
    "        \"\"\"Sample from q(x_t | x_0) - the forward diffusion process.\"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "        \n",
    "        sqrt_alphas_cumprod_t = self._extract(self.sqrt_alphas_cumprod, t, x_0.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_0.shape)\n",
    "        \n",
    "        return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "    \n",
    "    def _extract(self, a, t, x_shape):\n",
    "        \"\"\"Extract values from a at indices t.\"\"\"\n",
    "        batch_size = t.shape[0]\n",
    "        out = a.gather(-1, t)\n",
    "        return out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
    "    \n",
    "    def to(self, device):\n",
    "        \"\"\"Move all tensors to device.\"\"\"\n",
    "        self.betas = self.betas.to(device)\n",
    "        self.alphas = self.alphas.to(device)\n",
    "        self.alphas_cumprod = self.alphas_cumprod.to(device)\n",
    "        self.alphas_cumprod_prev = self.alphas_cumprod_prev.to(device)\n",
    "        self.sqrt_alphas_cumprod = self.sqrt_alphas_cumprod.to(device)\n",
    "        self.sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod.to(device)\n",
    "        self.posterior_variance = self.posterior_variance.to(device)\n",
    "        self.posterior_log_variance_clipped = self.posterior_log_variance_clipped.to(device)\n",
    "        self.posterior_mean_coef1 = self.posterior_mean_coef1.to(device)\n",
    "        self.posterior_mean_coef2 = self.posterior_mean_coef2.to(device)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. U-Net Architecture for Time Series\n",
    "\n",
    "We implement a 1D U-Net with time embeddings for noise prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    \"\"\"Sinusoidal position embeddings for timestep encoding.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Convolutional block with GroupNorm and SiLU activation.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
    "        \n",
    "        if up:\n",
    "            self.conv1 = nn.Conv1d(2 * in_ch, out_ch, 3, padding=1)\n",
    "            self.transform = nn.ConvTranspose1d(out_ch, out_ch, 4, 2, 1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv1d(in_ch, out_ch, 3, padding=1)\n",
    "            self.transform = nn.Conv1d(out_ch, out_ch, 4, 2, 1)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, 3, padding=1)\n",
    "        self.bnorm1 = nn.GroupNorm(8, out_ch)\n",
    "        self.bnorm2 = nn.GroupNorm(8, out_ch)\n",
    "        self.relu = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # First conv\n",
    "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
    "        \n",
    "        # Time embedding\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        time_emb = time_emb[:, :, None]  # Extend to 1D\n",
    "        h = h + time_emb\n",
    "        \n",
    "        # Second conv\n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        \n",
    "        # Down or upsample\n",
    "        return self.transform(h)\n",
    "\n",
    "\n",
    "class UNet1D(nn.Module):\n",
    "    \"\"\"1D U-Net for time series diffusion.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=1, out_channels=1, time_emb_dim=128, \n",
    "                 base_channels=64, channel_mults=(1, 2, 4)):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # Initial projection\n",
    "        self.conv0 = nn.Conv1d(in_channels, base_channels, 3, padding=1)\n",
    "        \n",
    "        # Downsampling\n",
    "        self.downs = nn.ModuleList()\n",
    "        channels = [base_channels]\n",
    "        in_ch = base_channels\n",
    "        \n",
    "        for mult in channel_mults:\n",
    "            out_ch = base_channels * mult\n",
    "            self.downs.append(Block(in_ch, out_ch, time_emb_dim))\n",
    "            channels.append(out_ch)\n",
    "            in_ch = out_ch\n",
    "        \n",
    "        # Middle\n",
    "        self.mid1 = nn.Conv1d(in_ch, in_ch, 3, padding=1)\n",
    "        self.mid2 = nn.Conv1d(in_ch, in_ch, 3, padding=1)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.ups = nn.ModuleList()\n",
    "        for mult in reversed(channel_mults):\n",
    "            out_ch = base_channels * mult\n",
    "            self.ups.append(Block(in_ch, out_ch, time_emb_dim, up=True))\n",
    "            in_ch = out_ch\n",
    "        \n",
    "        # Output\n",
    "        self.output = nn.Conv1d(base_channels, out_channels, 1)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # Time embedding\n",
    "        t = self.time_mlp(t)\n",
    "        \n",
    "        # Initial conv\n",
    "        x = self.conv0(x)\n",
    "        \n",
    "        # Downsample\n",
    "        residuals = [x]\n",
    "        for down in self.downs:\n",
    "            x = down(x, t)\n",
    "            residuals.append(x)\n",
    "        \n",
    "        # Middle\n",
    "        x = F.silu(self.mid1(x))\n",
    "        x = F.silu(self.mid2(x))\n",
    "        \n",
    "        # Upsample\n",
    "        for up in self.ups:\n",
    "            residual = residuals.pop()\n",
    "            # Handle size mismatch\n",
    "            if x.shape[-1] != residual.shape[-1]:\n",
    "                x = F.interpolate(x, size=residual.shape[-1], mode='nearest')\n",
    "            x = torch.cat((x, residual), dim=1)\n",
    "            x = up(x, t)\n",
    "        \n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simpler MLP-based Denoiser (for faster experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDenoiser(nn.Module):\n",
    "    \"\"\"Simple MLP-based denoiser for 1D time series.\"\"\"\n",
    "    \n",
    "    def __init__(self, seq_length, hidden_dim=256, time_emb_dim=64, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Main network\n",
    "        self.input_proj = nn.Linear(seq_length + hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.1)\n",
    "            ))\n",
    "        \n",
    "        self.output_proj = nn.Linear(hidden_dim, seq_length)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # x: [batch, seq_length] or [batch, 1, seq_length]\n",
    "        if x.dim() == 3:\n",
    "            x = x.squeeze(1)\n",
    "        \n",
    "        # Time embedding\n",
    "        t_emb = self.time_mlp(t)\n",
    "        \n",
    "        # Concatenate input with time embedding\n",
    "        h = torch.cat([x, t_emb], dim=-1)\n",
    "        h = self.input_proj(h)\n",
    "        \n",
    "        # Apply layers with residual connections\n",
    "        for layer in self.layers:\n",
    "            h = h + layer(h)\n",
    "        \n",
    "        return self.output_proj(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, diffusion, optimizer, x_0):\n",
    "    \"\"\"Single training step.\"\"\"\n",
    "    batch_size = x_0.shape[0]\n",
    "    \n",
    "    # Sample random timesteps\n",
    "    t = torch.randint(0, diffusion.num_timesteps, (batch_size,), device=x_0.device).long()\n",
    "    \n",
    "    # Sample noise\n",
    "    noise = torch.randn_like(x_0)\n",
    "    \n",
    "    # Get noisy samples\n",
    "    x_t = diffusion.q_sample(x_0, t, noise)\n",
    "    \n",
    "    # Predict noise\n",
    "    noise_pred = model(x_t, t.float())\n",
    "    \n",
    "    # Ensure shapes match\n",
    "    if noise_pred.dim() != noise.dim():\n",
    "        if noise_pred.dim() == 2 and noise.dim() == 3:\n",
    "            noise = noise.squeeze(1)\n",
    "        elif noise_pred.dim() == 3 and noise.dim() == 2:\n",
    "            noise_pred = noise_pred.squeeze(1)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = F.mse_loss(noise_pred, noise)\n",
    "    \n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train(model, diffusion, dataloader, epochs=100, lr=1e-4):\n",
    "    \"\"\"Full training loop.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            x_0 = batch[0].to(device)\n",
    "            loss = train_step(model, diffusion, optimizer, x_0)\n",
    "            epoch_losses.append(loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss = {avg_loss:.6f}\")\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sampling (DDPM and DDIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ddpm_sample(model, diffusion, shape, device):\n",
    "    \"\"\"Sample using DDPM (slow but high quality).\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Start from pure noise\n",
    "    x = torch.randn(shape, device=device)\n",
    "    \n",
    "    for t in tqdm(reversed(range(diffusion.num_timesteps)), desc=\"DDPM Sampling\", total=diffusion.num_timesteps):\n",
    "        t_batch = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
    "        \n",
    "        # Predict noise\n",
    "        noise_pred = model(x, t_batch.float())\n",
    "        if noise_pred.dim() == 2:\n",
    "            noise_pred = noise_pred.unsqueeze(1)\n",
    "        \n",
    "        # Get diffusion parameters\n",
    "        alpha = diffusion.alphas[t]\n",
    "        alpha_cumprod = diffusion.alphas_cumprod[t]\n",
    "        beta = diffusion.betas[t]\n",
    "        \n",
    "        # Compute mean\n",
    "        mean = (1 / torch.sqrt(alpha)) * (x - (beta / torch.sqrt(1 - alpha_cumprod)) * noise_pred)\n",
    "        \n",
    "        # Add noise (except for t=0)\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "            sigma = torch.sqrt(beta)\n",
    "            x = mean + sigma * noise\n",
    "        else:\n",
    "            x = mean\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ddim_sample(model, diffusion, shape, device, num_steps=50, eta=0.0):\n",
    "    \"\"\"\n",
    "    Sample using DDIM (faster, controllable stochasticity).\n",
    "    \n",
    "    Args:\n",
    "        eta: 0 = deterministic, 1 = DDPM-like stochasticity\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create timestep schedule (subset of full schedule)\n",
    "    step_size = diffusion.num_timesteps // num_steps\n",
    "    timesteps = list(range(0, diffusion.num_timesteps, step_size))\n",
    "    timesteps = list(reversed(timesteps))\n",
    "    \n",
    "    # Start from pure noise\n",
    "    x = torch.randn(shape, device=device)\n",
    "    \n",
    "    for i in tqdm(range(len(timesteps)), desc=\"DDIM Sampling\"):\n",
    "        t = timesteps[i]\n",
    "        t_prev = timesteps[i + 1] if i < len(timesteps) - 1 else 0\n",
    "        \n",
    "        t_batch = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
    "        \n",
    "        # Predict noise\n",
    "        noise_pred = model(x, t_batch.float())\n",
    "        if noise_pred.dim() == 2:\n",
    "            noise_pred = noise_pred.unsqueeze(1)\n",
    "        \n",
    "        # Get alpha values\n",
    "        alpha_cumprod_t = diffusion.alphas_cumprod[t]\n",
    "        alpha_cumprod_t_prev = diffusion.alphas_cumprod[t_prev] if t_prev >= 0 else torch.tensor(1.0)\n",
    "        \n",
    "        # Predict x_0\n",
    "        x_0_pred = (x - torch.sqrt(1 - alpha_cumprod_t) * noise_pred) / torch.sqrt(alpha_cumprod_t)\n",
    "        \n",
    "        # Compute variance\n",
    "        sigma = eta * torch.sqrt((1 - alpha_cumprod_t_prev) / (1 - alpha_cumprod_t)) * torch.sqrt(1 - alpha_cumprod_t / alpha_cumprod_t_prev)\n",
    "        \n",
    "        # Direction pointing to x_t\n",
    "        dir_xt = torch.sqrt(1 - alpha_cumprod_t_prev - sigma**2) * noise_pred\n",
    "        \n",
    "        # Compute x_{t-1}\n",
    "        x = torch.sqrt(alpha_cumprod_t_prev) * x_0_pred + dir_xt\n",
    "        \n",
    "        if t_prev > 0 and eta > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "            x = x + sigma * noise\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Synthetic Financial Data and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic financial time series\n",
    "def generate_synthetic_returns(n_samples=5000, seq_length=64):\n",
    "    \"\"\"Generate synthetic returns with realistic properties.\"\"\"\n",
    "    returns = np.zeros((n_samples, seq_length))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Base volatility\n",
    "        base_vol = np.random.uniform(0.01, 0.03)\n",
    "        \n",
    "        # Generate with volatility clustering\n",
    "        vol = base_vol\n",
    "        for t in range(seq_length):\n",
    "            if t > 0:\n",
    "                # GARCH-like volatility\n",
    "                vol = 0.9 * vol + 0.1 * base_vol * (1 + abs(returns[i, t-1]) / base_vol)\n",
    "            returns[i, t] = vol * np.random.randn()\n",
    "    \n",
    "    return returns\n",
    "\n",
    "# Generate data\n",
    "seq_length = 64\n",
    "returns = generate_synthetic_returns(n_samples=5000, seq_length=seq_length)\n",
    "\n",
    "# Normalize\n",
    "returns_mean = returns.mean()\n",
    "returns_std = returns.std()\n",
    "returns_normalized = (returns - returns_mean) / returns_std\n",
    "\n",
    "# Create dataset\n",
    "X = torch.tensor(returns_normalized, dtype=torch.float32)\n",
    "dataset = TensorDataset(X)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Mean: {returns.mean():.6f}, Std: {returns.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and diffusion\n",
    "diffusion = GaussianDiffusion(num_timesteps=500, beta_schedule='cosine').to(device)\n",
    "model = MLPDenoiser(seq_length=seq_length, hidden_dim=256, time_emb_dim=64, num_layers=4).to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "losses = train(model, diffusion, dataloader, epochs=100, lr=1e-4)\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare DDPM vs DDIM Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample with both methods\n",
    "n_samples = 100\n",
    "\n",
    "# DDPM (slow but full quality)\n",
    "print(\"Sampling with DDPM (500 steps)...\")\n",
    "ddpm_samples = ddpm_sample(model, diffusion, (n_samples, seq_length), device)\n",
    "\n",
    "# DDIM (fast)\n",
    "print(\"\\nSampling with DDIM (50 steps)...\")\n",
    "ddim_samples = ddim_sample(model, diffusion, (n_samples, seq_length), device, num_steps=50, eta=0.0)\n",
    "\n",
    "# Convert to numpy\n",
    "ddpm_samples = ddpm_samples.cpu().numpy()\n",
    "ddim_samples = ddim_samples.cpu().numpy()\n",
    "\n",
    "# Denormalize\n",
    "ddpm_samples = ddpm_samples * returns_std + returns_mean\n",
    "ddim_samples = ddim_samples * returns_std + returns_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Sample trajectories\n",
    "for i in range(5):\n",
    "    axes[0, 0].plot(np.cumsum(returns[i]), alpha=0.7)\n",
    "axes[0, 0].set_title('Real Samples')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].set_ylabel('Cumulative Return')\n",
    "\n",
    "for i in range(5):\n",
    "    axes[0, 1].plot(np.cumsum(ddpm_samples[i]), alpha=0.7)\n",
    "axes[0, 1].set_title('DDPM Samples (500 steps)')\n",
    "axes[0, 1].set_xlabel('Time')\n",
    "\n",
    "for i in range(5):\n",
    "    axes[0, 2].plot(np.cumsum(ddim_samples[i]), alpha=0.7)\n",
    "axes[0, 2].set_title('DDIM Samples (50 steps)')\n",
    "axes[0, 2].set_xlabel('Time')\n",
    "\n",
    "# Distribution comparison\n",
    "axes[1, 0].hist(returns.flatten(), bins=100, density=True, alpha=0.7, label='Real')\n",
    "axes[1, 0].hist(ddpm_samples.flatten(), bins=100, density=True, alpha=0.7, label='DDPM')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_title('Distribution: Real vs DDPM')\n",
    "\n",
    "axes[1, 1].hist(returns.flatten(), bins=100, density=True, alpha=0.7, label='Real')\n",
    "axes[1, 1].hist(ddim_samples.flatten(), bins=100, density=True, alpha=0.7, label='DDIM')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_title('Distribution: Real vs DDIM')\n",
    "\n",
    "# QQ plot\n",
    "real_sorted = np.sort(returns.flatten())\n",
    "ddpm_sorted = np.sort(ddpm_samples.flatten())\n",
    "ddim_sorted = np.sort(ddim_samples.flatten())\n",
    "\n",
    "idx = np.linspace(0, len(real_sorted)-1, 1000).astype(int)\n",
    "axes[1, 2].scatter(real_sorted[idx], ddpm_sorted[idx], alpha=0.3, s=10, label='DDPM')\n",
    "axes[1, 2].scatter(real_sorted[idx], ddim_sorted[idx], alpha=0.3, s=10, label='DDIM')\n",
    "axes[1, 2].plot([real_sorted.min(), real_sorted.max()], \n",
    "                [real_sorted.min(), real_sorted.max()], 'k--')\n",
    "axes[1, 2].set_title('Q-Q Plot')\n",
    "axes[1, 2].set_xlabel('Real Quantiles')\n",
    "axes[1, 2].set_ylabel('Generated Quantiles')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize the Denoising Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_denoising(model, diffusion, device, num_viz_steps=10):\n",
    "    \"\"\"Visualize the denoising process.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Start from noise\n",
    "    x = torch.randn(1, seq_length, device=device)\n",
    "    \n",
    "    # Store intermediate results\n",
    "    step_size = diffusion.num_timesteps // num_viz_steps\n",
    "    intermediates = [x.cpu().numpy().flatten()]\n",
    "    timesteps_viz = [diffusion.num_timesteps]\n",
    "    \n",
    "    for t in reversed(range(diffusion.num_timesteps)):\n",
    "        t_batch = torch.full((1,), t, device=device, dtype=torch.long)\n",
    "        \n",
    "        # Predict noise\n",
    "        noise_pred = model(x, t_batch.float())\n",
    "        if noise_pred.dim() == 2:\n",
    "            noise_pred = noise_pred.unsqueeze(1)\n",
    "        \n",
    "        # Get parameters\n",
    "        alpha = diffusion.alphas[t]\n",
    "        alpha_cumprod = diffusion.alphas_cumprod[t]\n",
    "        beta = diffusion.betas[t]\n",
    "        \n",
    "        # Denoise\n",
    "        mean = (1 / torch.sqrt(alpha)) * (x - (beta / torch.sqrt(1 - alpha_cumprod)) * noise_pred)\n",
    "        \n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "            x = mean + torch.sqrt(beta) * noise\n",
    "        else:\n",
    "            x = mean\n",
    "        \n",
    "        # Store intermediate\n",
    "        if t % step_size == 0 or t == 0:\n",
    "            intermediates.append(x.cpu().numpy().flatten())\n",
    "            timesteps_viz.append(t)\n",
    "    \n",
    "    return intermediates, timesteps_viz\n",
    "\n",
    "# Visualize\n",
    "intermediates, timesteps_viz = visualize_denoising(model, diffusion, device)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (sample, t) in enumerate(zip(intermediates[:10], timesteps_viz[:10])):\n",
    "    # Denormalize\n",
    "    sample_denorm = sample * returns_std + returns_mean\n",
    "    axes[i].plot(np.cumsum(sample_denorm), 'b-', linewidth=1.5)\n",
    "    axes[i].set_title(f't = {t}')\n",
    "    axes[i].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[i].set_xlabel('Time')\n",
    "    if i % 5 == 0:\n",
    "        axes[i].set_ylabel('Cumulative Return')\n",
    "\n",
    "plt.suptitle('Denoising Process: From Noise to Financial Time Series', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "1. **DDPM** learns to reverse a gradual noising process\n",
    "2. **U-Net** architecture can be adapted for 1D time series\n",
    "3. **DDIM** provides 10x faster sampling with minimal quality loss\n",
    "4. **Noise schedule** (cosine vs linear) affects quality significantly\n",
    "5. Generated samples capture distribution statistics well\n",
    "\n",
    "### Next Steps:\n",
    "- Notebook 03: TimeGrad for conditional forecasting\n",
    "- Notebook 04: CSDI for imputation and forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
