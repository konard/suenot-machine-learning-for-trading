# Диффузионные модели для синтетических временных рядов и прогнозирования

Эта глава представляет **диффузионные модели** для финансовых временных рядов. Изначально разработанные для генерации изображений (Stable Diffusion, DALL-E), диффузионные модели стали мощной альтернативой GAN для создания синтетических финансовых данных и вероятностного прогнозирования.

<p align="center">
<img src="https://i.imgur.com/YqKxZ8N.png" width="70%">
</p>

## Содержание

1. [Диффузионные модели: от изображений к временным рядам](#диффузионные-модели-от-изображений-к-временным-рядам)
    * [Интуиция диффузии](#интуиция-диффузии)
    * [Прямой процесс: добавление шума](#прямой-процесс-добавление-шума)
    * [Обратный процесс: удаление шума](#обратный-процесс-удаление-шума)
    * [Расписания шума](#расписания-шума)
2. [Ключевые архитектуры для временных рядов](#ключевые-архитектуры-для-временных-рядов)
    * [TimeGrad: авторегрессионная диффузия](#timegrad-авторегрессионная-диффузия)
    * [CSDI: условная score-based диффузия](#csdi-условная-score-based-диффузия)
    * [Diffusion-TS: декомпозированные представления](#diffusion-ts-декомпозированные-представления)
    * [TimeDiff и последние достижения (2024-2025)](#timediff-и-последние-достижения-2024-2025)
3. [Примеры кода](#примеры-кода)
4. [Реализация на Rust](#реализация-на-rust)
5. [Практические соображения](#практические-соображения)
6. [Ресурсы](#ресурсы)

## Диффузионные модели: от изображений к временным рядам

Диффузионные модели — класс генеративных моделей, которые учатся генерировать данные, обращая постепенный процесс зашумления. В отличие от GAN, которые обучаются через состязательный процесс, диффузионные модели учатся **удалять шум** шаг за шагом.

### Интуиция диффузии

Ключевая идея: легче научиться небольшим шагам удаления шума, чем генерировать данные за один проход:

1. **Прямой процесс**: постепенно добавляем гауссовский шум к данным, пока они не станут чистым шумом
2. **Обратный процесс**: учимся отменять каждый шаг зашумления, восстанавливая исходные данные

Преимущества перед GAN:
- **Стабильность обучения**: нет состязательной динамики, mode collapse редок
- **Качество**: часто производит более качественные образцы
- **Квантификация неопределённости**: естественная вероятностная интерпретация

### Прямой процесс: добавление шума

Прямой диффузионный процесс — цепь Маркова с постепенным добавлением гауссовского шума:

$$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)$$

Где:
- $x_0$ — исходные данные
- $x_t$ — зашумлённые данные на шаге $t$
- $\beta_t$ — расписание шума (обычно $\beta_t \in [0.0001, 0.02]$)
- $T$ — общее количество шагов диффузии (обычно 1000)

Ключевое свойство позволяет прямую выборку на любом шаге:

$$q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t) I)$$

где $\bar{\alpha}_t = \prod_{s=1}^{t} (1-\beta_s)$

### Обратный процесс: удаление шума

Обратный процесс учится удалять шум:

$$p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$$

На практике мы обучаем нейронную сеть $\epsilon_\theta(x_t, t)$ предсказывать добавленный шум на каждом шаге. Целевая функция:

$$\mathcal{L} = \mathbb{E}_{t, x_0, \epsilon} \left[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \right]$$

### Расписания шума

Выбор расписания шума $\beta_t$ существенно влияет на производительность:

| Расписание | Формула | Характеристики |
|------------|---------|----------------|
| **Линейное** | $\beta_t = \beta_1 + \frac{t-1}{T-1}(\beta_T - \beta_1)$ | Простое, хорошо для изображений |
| **Косинусное** | $\bar{\alpha}_t = \frac{f(t)}{f(0)}$, $f(t) = \cos^2(\frac{t/T + s}{1+s} \cdot \frac{\pi}{2})$ | Лучше для малых последовательностей |
| **Сигмоидное** | $\beta_t = \sigma(-6 + 12\frac{t}{T})$ | Плавные переходы |

## Ключевые архитектуры для временных рядов

### TimeGrad: авторегрессионная диффузия

[TimeGrad](https://arxiv.org/abs/2101.12072) (Rasul et al., 2021) комбинирует авторегрессию с диффузией:

```
Вход: x_{1:t} (исторические наблюдения)
├── RNN Encoder → Скрытое состояние h_t
├── Диффузионный процесс, обусловленный на h_t
└── Выход: p(x_{t+1:t+τ} | x_{1:t})
```

**Ключевые особенности**:
- Использует RNN/LSTM для кодирования истории
- Диффузия генерирует будущее, обусловленное на скрытом состоянии
- Авторегрессия: генерирует по одному шагу за раз

**Ограничения**: накопление ошибок, медленный инференс.

### CSDI: условная score-based диффузия

[CSDI](https://github.com/ermongroup/CSDI) (Tashiro et al., NeurIPS 2021) использует attention для обуславливания:

```
Вход: Частично наблюдаемый временной ряд с маской
├── Temporal Attention (по времени)
├── Feature Attention (по переменным)
├── Score-based диффузия, обусловленная на наблюдаемых значениях
└── Выход: Заполненные/прогнозные значения с неопределённостью
```

**Ключевые особенности**:
- Self-supervised обучение со случайным маскированием
- Работает и для imputation, и для forecasting
- **40-65% улучшение** над существующими вероятностными методами
- Генерирует вероятностные прогнозы (множественные samples)

### Diffusion-TS: декомпозированные представления

[Diffusion-TS](https://github.com/Y-debug-sys/Diffusion-TS) (ICLR 2024) вводит интерпретируемую декомпозицию:

```
Вход: Временной ряд x
├── Encoder-Decoder Transformer
├── Декомпозиция:
│   ├── Тренд: Полиномиальная регрессия
│   └── Сезонность: Ряды Фурье
├── Диффузия в декомпозированном пространстве
└── Выход: Интерпретируемый синтетический ряд
```

**Ключевые особенности**:
- Реконструирует samples напрямую (не шум)
- Fourier loss для спектральной точности
- Одна архитектура для генерации, прогнозирования, imputation
- **State-of-the-art** на Stocks, Energy, ETTh датасетах

### TimeDiff и последние достижения (2024-2025)

Последние разработки решают ключевые ограничения:

| Метод | Инновация | Производительность |
|-------|-----------|-------------------|
| **TimeDiff** | Условная диффузия на границе прошлое-будущее | 9-47% улучшение |
| **ARMD** | Авторегрессионная движущаяся диффузия | Лучший MSE на Exchange Rates |
| **SimDiff** (2025) | Упрощённая архитектура | Сравнимо с 10x меньше параметров |
| **MG-TSD** | Мультигранулярные временные структуры | SOTA на долгосрочном прогнозе |
| **S²DBM** | Brownian Bridge динамика | Естественные граничные условия |

## Примеры кода

| Ноутбук | Описание |
|---------|----------|
| [01_diffusion_fundamentals.ipynb](01_diffusion_fundamentals.ipynb) | Основы диффузии, noise schedules, ELBO |
| [02_ddpm_from_scratch.ipynb](02_ddpm_from_scratch.ipynb) | DDPM с нуля на PyTorch |
| [03_timegrad_crypto.ipynb](03_timegrad_crypto.ipynb) | TimeGrad для прогнозирования криптовалют |
| [04_csdi_imputation_forecasting.ipynb](04_csdi_imputation_forecasting.ipynb) | CSDI для imputation и forecasting |
| [05_diffusion_ts_synthetic.ipynb](05_diffusion_ts_synthetic.ipynb) | Генерация синтетических крипто-данных |
| [06_diffusion_vs_gans.ipynb](06_diffusion_vs_gans.ipynb) | Сравнение с GANs (Глава 21) |
| [07_bitcoin_pipeline.ipynb](07_bitcoin_pipeline.ipynb) | Полный pipeline для Bitcoin |

## Реализация на Rust

Директория [rust_diffusion_crypto](rust_diffusion_crypto/) содержит Rust-реализацию с использованием `tch-rs` (PyTorch bindings):

```
rust_diffusion_crypto/
├── Cargo.toml
├── README.md
├── src/
│   ├── lib.rs
│   ├── main.rs
│   ├── data/           # Bybit API клиент, предобработка
│   ├── model/          # DDPM, U-Net, noise schedules
│   ├── training/       # Training loop, losses
│   └── utils/          # Конфиг, чекпоинты
└── examples/
    ├── fetch_data.rs
    ├── train_ddpm.rs
    └── forecast.rs
```

Смотрите [rust_diffusion_crypto/README.md](rust_diffusion_crypto/README.md) для подробностей.

## Практические соображения

### Когда использовать диффузионные модели

**Хорошие кейсы**:
- Генерация синтетических данных для бэктестинга
- Вероятностное прогнозирование с неопределённостью
- Заполнение пропущенных данных
- Генерация сценариев для анализа рисков
- Когда нужно разнообразие в сгенерированных samples

**Не идеально для**:
- Real-time / low-latency предсказаний (медленный инференс)
- Ограниченных вычислительных ресурсов
- Когда критична интерпретируемость модели
- Очень коротких последовательностей (<24 timesteps)

### Вычислительные требования

| Задача | GPU память | Время обучения | Время инференса |
|--------|------------|----------------|-----------------|
| Простой DDPM | 4GB | 2-4 часа | 100мс/sample |
| TimeGrad | 8GB | 8-12 часов | 500мс/sample |
| CSDI | 12GB | 12-24 часа | 200мс/sample |
| Diffusion-TS | 8GB | 6-10 часов | 150мс/sample |

### Техники оптимизации

1. **DDIM Sampling**: уменьшение шагов с 1000 до 50-100 с минимальной потерей качества
2. **Token Merging**: [tomesd](https://github.com/dbolya/tomesd) ускоряет в 1.24x
3. **Distillation**: обучение меньших student моделей
4. **Caching**: кэширование attention вычислений между шагами

## Ресурсы

### Статьи

- [Denoising Diffusion Probabilistic Models (DDPM)](https://arxiv.org/abs/2006.11239), Ho et al., 2020
- [TimeGrad: Autoregressive Denoising Diffusion](https://arxiv.org/abs/2101.12072), Rasul et al., 2021
- [CSDI: Conditional Score-based Diffusion for Imputation](https://arxiv.org/abs/2107.03502), Tashiro et al., NeurIPS 2021
- [Diffusion-TS: Interpretable Diffusion for Time Series](https://openreview.net/forum?id=4h1apFjO99), ICLR 2024
- [Diffusion Models for Time Series Forecasting: A Survey](https://arxiv.org/abs/2401.03006), Meijer et al., 2024

### Реализации

- [ermongroup/CSDI](https://github.com/ermongroup/CSDI) — официальный CSDI
- [Y-debug-sys/Diffusion-TS](https://github.com/Y-debug-sys/Diffusion-TS) — Diffusion-TS
- [amazon-science/unconditional-time-series-diffusion](https://github.com/amazon-science/unconditional-time-series-diffusion) — TSDiff

### Связанные главы

- [Глава 19: RNN для мультивариантных временных рядов](../19_recurrent_neural_nets) — основы LSTM/GRU
- [Глава 20: Автоэнкодеры для факторов риска](../20_autoencoders_for_conditional_risk_factors) — модели латентного пространства
- [Глава 21: GAN для синтетических временных рядов](../21_gans_for_synthetic_time_series) — альтернативный генеративный подход
